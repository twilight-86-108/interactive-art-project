# src/vision/face_detector.py - ä¿®æ­£ç‰ˆ
import cv2
import numpy as np
import mediapipe as mp
from mediapipe.python.solutions import face_mesh, drawing_utils, drawing_styles
import logging
from typing import Optional, Dict, Any, List, Tuple, Union
from dataclasses import dataclass
from enum import Enum

class FaceDetectionQuality(Enum):
    """é¡”æ¤œå‡ºå“è³ªãƒ¬ãƒ™ãƒ«"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"

@dataclass
class FaceDetectionResult:
    """é¡”æ¤œå‡ºçµæœãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    face_detected: bool
    face_landmarks: Optional[Any] = None
    face_center: Optional[Tuple[float, float, float]] = None
    face_distance: float = float('inf')
    confidence: float = 0.0
    bounding_box: Optional[Tuple[int, int, int, int]] = None
    landmarks_2d: Optional[List[Tuple[float, float]]] = None
    landmarks_3d: Optional[List[Tuple[float, float, float]]] = None

class FaceDetector:
    """MediaPipeé¡”æ¤œå‡ºã‚¯ãƒ©ã‚¹ï¼ˆä¿®æ­£ç‰ˆï¼‰"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # MediaPipeåˆæœŸåŒ–
        self._init_mediapipe()
        
        # æ¤œå‡ºå±¥æ­´ï¼ˆå¹³æ»‘åŒ–ç”¨ï¼‰
        self.detection_history = []
        self.max_history = 10
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
        self.processing_times = []
        self.detection_counts = {'success': 0, 'failure': 0}
        
        # å“è³ªåˆ¶å¾¡
        self.current_quality = FaceDetectionQuality.HIGH
        self.adaptive_quality = config.get('adaptive_quality', True)
        
        self.logger.info("é¡”æ¤œå‡ºå™¨ãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ")
    
    def _init_mediapipe(self):
        """MediaPipeåˆæœŸåŒ–ï¼ˆæœ€æ–°APIå¯¾å¿œï¼‰"""
        try:
            # æ˜ç¤ºçš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§å‹ã‚¨ãƒ©ãƒ¼å›é¿
            self.mp_face_mesh = face_mesh
            self.mp_drawing = drawing_utils
            self.mp_drawing_styles = drawing_styles
            
            # FaceMeshè¨­å®šå–å¾—
            face_config = self.config.get('face_detection', {})
            
            # FaceMeshã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
            self.face_mesh = self.mp_face_mesh.FaceMesh(
                static_image_mode=False,
                max_num_faces=face_config.get('max_num_faces', 1),
                refine_landmarks=face_config.get('refine_landmarks', True),
                min_detection_confidence=face_config.get('min_detection_confidence', 0.7),
                min_tracking_confidence=face_config.get('min_tracking_confidence', 0.5)
            )
            
            self.logger.info("MediaPipe FaceMeshåˆæœŸåŒ–æˆåŠŸ")
            
        except Exception as e:
            self.logger.error(f"MediaPipeåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise RuntimeError(f"MediaPipeåˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    
    def detect_face(self, frame: np.ndarray) -> FaceDetectionResult:
        """
        é¡”æ¤œå‡ºãƒ¡ã‚¤ãƒ³å‡¦ç†
        
        Args:
            frame: å…¥åŠ›ç”»åƒãƒ•ãƒ¬ãƒ¼ãƒ  (BGRå½¢å¼)
            
        Returns:
            FaceDetectionResult: æ¤œå‡ºçµæœ
        """
        import time
        start_time = time.time()
        
        try:
            # å…¥åŠ›æ¤œè¨¼
            if frame is None or frame.size == 0:
                self.logger.warning("ç„¡åŠ¹ãªãƒ•ãƒ¬ãƒ¼ãƒ ãŒå…¥åŠ›ã•ã‚Œã¾ã—ãŸ")
                return FaceDetectionResult(face_detected=False)
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ å‰å‡¦ç†
            processed_frame = self._preprocess_frame(frame)
            
            # MediaPipeå‡¦ç†
            results = self.face_mesh.process(processed_frame)
            
            # çµæœå‡¦ç†
            detection_result = self._process_face_results(
                results, 
                tuple(frame.shape)  # æ˜ç¤ºçš„ã«tupleã«ã‚­ãƒ£ã‚¹ãƒˆ
            )
            
            # å±¥æ­´æ›´æ–°
            self._update_detection_history(detection_result)
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨˜éŒ²
            processing_time = time.time() - start_time
            self.processing_times.append(processing_time)
            if len(self.processing_times) > 100:
                self.processing_times.pop(0)
            
            # çµ±è¨ˆæ›´æ–°
            if detection_result.face_detected:
                self.detection_counts['success'] += 1
            else:
                self.detection_counts['failure'] += 1
            
            # é©å¿œçš„å“è³ªåˆ¶å¾¡
            if self.adaptive_quality:
                self._adjust_quality_if_needed(processing_time)
            
            return detection_result
            
        except Exception as e:
            self.logger.error(f"é¡”æ¤œå‡ºå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return FaceDetectionResult(face_detected=False)
    
    def _preprocess_frame(self, frame: np.ndarray) -> np.ndarray:
        """ãƒ•ãƒ¬ãƒ¼ãƒ å‰å‡¦ç†"""
        try:
            # BGR to RGBå¤‰æ›
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            # å“è³ªã«å¿œã˜ãŸãƒªã‚µã‚¤ã‚º
            if self.current_quality == FaceDetectionQuality.LOW:
                height, width = frame.shape[:2]
                new_width = min(640, width)
                new_height = int(height * (new_width / width))
                rgb_frame = cv2.resize(rgb_frame, (new_width, new_height))
            elif self.current_quality == FaceDetectionQuality.MEDIUM:
                height, width = frame.shape[:2]
                new_width = min(1280, width)
                new_height = int(height * (new_width / width))
                rgb_frame = cv2.resize(rgb_frame, (new_width, new_height))
            # HIGHå“è³ªã®å ´åˆã¯å…ƒã®ã‚µã‚¤ã‚ºã‚’ç¶­æŒ
            
            return rgb_frame
            
        except Exception as e:
            self.logger.warning(f"ãƒ•ãƒ¬ãƒ¼ãƒ å‰å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¿”ã™ï¼ˆè‰²å¤‰æ›ã®ã¿ï¼‰
            return cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    
    def _process_face_results(self, results: Any, frame_shape: Tuple[int, ...]) -> FaceDetectionResult:
        """
        MediaPipeçµæœå‡¦ç†
        
        Args:
            results: MediaPipeå‡¦ç†çµæœ
            frame_shape: ãƒ•ãƒ¬ãƒ¼ãƒ å½¢çŠ¶ (height, width, channels)
            
        Returns:
            FaceDetectionResult: å‡¦ç†ã•ã‚ŒãŸæ¤œå‡ºçµæœ
        """
        try:
            # ãƒ•ãƒ¬ãƒ¼ãƒ å½¢çŠ¶ã®å®‰å…¨ãªå‡¦ç†
            if len(frame_shape) >= 2:
                height, width = frame_shape[0], frame_shape[1]
                channels = frame_shape[2] if len(frame_shape) > 2 else 3
            else:
                self.logger.warning(f"ç„¡åŠ¹ãªãƒ•ãƒ¬ãƒ¼ãƒ å½¢çŠ¶: {frame_shape}")
                return FaceDetectionResult(face_detected=False)
            
            # é¡”ãŒæ¤œå‡ºã•ã‚Œãªã„å ´åˆ
            if not results.multi_face_landmarks:
                return FaceDetectionResult(face_detected=False)
            
            # æœ€åˆã®é¡”ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’å‡¦ç†ï¼ˆè¤‡æ•°é¡”å¯¾å¿œã¯å°†æ¥çš„ã«ï¼‰
            face_landmarks = results.multi_face_landmarks[0]
            
            # 2D/3Dãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯åº§æ¨™å–å¾—
            landmarks_2d = []
            landmarks_3d = []
            
            for landmark in face_landmarks.landmark:
                # æ­£è¦åŒ–åº§æ¨™ã‚’ãƒ”ã‚¯ã‚»ãƒ«åº§æ¨™ã«å¤‰æ›
                x_px = int(landmark.x * width)
                y_px = int(landmark.y * height)
                z = landmark.z  # ç›¸å¯¾çš„ãªæ·±åº¦
                
                landmarks_2d.append((landmark.x, landmark.y))
                landmarks_3d.append((landmark.x, landmark.y, z))
            
            # é¡”ã®ä¸­å¿ƒç‚¹è¨ˆç®—ï¼ˆé¼»å…ˆã‚’ä½¿ç”¨ï¼‰
            nose_tip_idx = 1  # MediaPipeã®é¼»å…ˆãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            if len(face_landmarks.landmark) > nose_tip_idx:
                nose_landmark = face_landmarks.landmark[nose_tip_idx]
                face_center = (nose_landmark.x, nose_landmark.y, nose_landmark.z)
                face_distance = abs(nose_landmark.z)
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…¨ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®é‡å¿ƒ
                center_x = sum(lm.x for lm in face_landmarks.landmark) / len(face_landmarks.landmark)
                center_y = sum(lm.y for lm in face_landmarks.landmark) / len(face_landmarks.landmark)
                center_z = sum(lm.z for lm in face_landmarks.landmark) / len(face_landmarks.landmark)
                face_center = (center_x, center_y, center_z)
                face_distance = abs(center_z)
            
            # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹è¨ˆç®—
            x_coords = [lm.x * width for lm in face_landmarks.landmark]
            y_coords = [lm.y * height for lm in face_landmarks.landmark]
            
            x_min, x_max = int(min(x_coords)), int(max(x_coords))
            y_min, y_max = int(min(y_coords)), int(max(y_coords))
            bounding_box = (x_min, y_min, x_max - x_min, y_max - y_min)
            
            # ä¿¡é ¼åº¦è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            confidence = self._calculate_detection_confidence(face_landmarks, frame_shape)
            
            return FaceDetectionResult(
                face_detected=True,
                face_landmarks=face_landmarks,
                face_center=face_center,
                face_distance=face_distance,
                confidence=confidence,
                bounding_box=bounding_box,
                landmarks_2d=landmarks_2d,
                landmarks_3d=landmarks_3d
            )
            
        except Exception as e:
            self.logger.error(f"é¡”çµæœå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return FaceDetectionResult(face_detected=False)
    
    def _calculate_detection_confidence(self, face_landmarks: Any, frame_shape: Tuple[int, ...]) -> float:
        """æ¤œå‡ºä¿¡é ¼åº¦è¨ˆç®—"""
        try:
            # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ•°ã«ã‚ˆã‚‹åŸºæœ¬ä¿¡é ¼åº¦
            landmark_count = len(face_landmarks.landmark)
            base_confidence = min(1.0, landmark_count / 468)  # MediaPipeã®æ¨™æº–ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ•°
            
            # é¡”ã®ã‚µã‚¤ã‚ºã«ã‚ˆã‚‹èª¿æ•´
            if len(frame_shape) >= 2:
                height, width = frame_shape[0], frame_shape[1]
                
                x_coords = [lm.x * width for lm in face_landmarks.landmark]
                y_coords = [lm.y * height for lm in face_landmarks.landmark]
                
                face_width = max(x_coords) - min(x_coords)
                face_height = max(y_coords) - min(y_coords)
                
                # ç›¸å¯¾çš„ãªé¡”ã‚µã‚¤ã‚º
                relative_face_size = (face_width * face_height) / (width * height)
                
                # é©åº¦ãªã‚µã‚¤ã‚ºã®é¡”ã«é«˜ã„ä¿¡é ¼åº¦
                if 0.05 <= relative_face_size <= 0.5:
                    size_confidence = 1.0
                elif relative_face_size < 0.05:
                    size_confidence = relative_face_size / 0.05
                else:
                    size_confidence = 0.5 / relative_face_size
                
                return min(1.0, base_confidence * size_confidence)
            
            return base_confidence
            
        except Exception as e:
            self.logger.warning(f"ä¿¡é ¼åº¦è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.5  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    
    def _update_detection_history(self, result: FaceDetectionResult):
        """æ¤œå‡ºå±¥æ­´æ›´æ–°"""
        self.detection_history.append(result)
        if len(self.detection_history) > self.max_history:
            self.detection_history.pop(0)
    
    def _adjust_quality_if_needed(self, processing_time: float):
        """é©å¿œçš„å“è³ªèª¿æ•´"""
        target_time = 0.033  # 30FPSç›¸å½“ã®å‡¦ç†æ™‚é–“
        
        if processing_time > target_time * 1.5:  # å‡¦ç†ãŒé…ã„
            if self.current_quality == FaceDetectionQuality.HIGH:
                self.current_quality = FaceDetectionQuality.MEDIUM
                self.logger.info("é¡”æ¤œå‡ºå“è³ªã‚’MEDIUMã«èª¿æ•´")
            elif self.current_quality == FaceDetectionQuality.MEDIUM:
                self.current_quality = FaceDetectionQuality.LOW
                self.logger.info("é¡”æ¤œå‡ºå“è³ªã‚’LOWã«èª¿æ•´")
        elif processing_time < target_time * 0.5:  # å‡¦ç†ãŒé€Ÿã„
            if self.current_quality == FaceDetectionQuality.LOW:
                self.current_quality = FaceDetectionQuality.MEDIUM
                self.logger.info("é¡”æ¤œå‡ºå“è³ªã‚’MEDIUMã«èª¿æ•´")
            elif self.current_quality == FaceDetectionQuality.MEDIUM:
                self.current_quality = FaceDetectionQuality.HIGH
                self.logger.info("é¡”æ¤œå‡ºå“è³ªã‚’HIGHã«èª¿æ•´")
    
    def get_smoothed_result(self) -> Optional[FaceDetectionResult]:
        """å±¥æ­´ãƒ™ãƒ¼ã‚¹å¹³æ»‘åŒ–çµæœå–å¾—"""
        if not self.detection_history:
            return None
        
        try:
            # æœ€è¿‘ã®æ¤œå‡ºæˆåŠŸçµæœã®ã¿ã‚’ä½¿ç”¨
            recent_successful = [
                result for result in self.detection_history[-5:] 
                if result.face_detected
            ]
            
            if not recent_successful:
                return FaceDetectionResult(face_detected=False)
            
            # å¹³å‡åº§æ¨™è¨ˆç®—
            avg_center_x = sum(r.face_center[0] for r in recent_successful) / len(recent_successful)
            avg_center_y = sum(r.face_center[1] for r in recent_successful) / len(recent_successful)
            avg_center_z = sum(r.face_center[2] for r in recent_successful) / len(recent_successful)
            
            avg_distance = sum(r.face_distance for r in recent_successful) / len(recent_successful)
            avg_confidence = sum(r.confidence for r in recent_successful) / len(recent_successful)
            
            return FaceDetectionResult(
                face_detected=True,
                face_center=(avg_center_x, avg_center_y, avg_center_z),
                face_distance=avg_distance,
                confidence=avg_confidence
            )
            
        except Exception as e:
            self.logger.warning(f"å¹³æ»‘åŒ–å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return self.detection_history[-1] if self.detection_history else None
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆå–å¾—"""
        if not self.processing_times:
            return {}
        
        total_detections = self.detection_counts['success'] + self.detection_counts['failure']
        
        return {
            'avg_processing_time': sum(self.processing_times) / len(self.processing_times),
            'max_processing_time': max(self.processing_times),
            'min_processing_time': min(self.processing_times),
            'detection_success_rate': self.detection_counts['success'] / max(1, total_detections),
            'total_detections': total_detections,
            'current_quality': self.current_quality.value,
            'fps_estimate': 1.0 / (sum(self.processing_times[-10:]) / min(10, len(self.processing_times)))
        }
    
    def draw_landmarks(self, frame: np.ndarray, result: FaceDetectionResult) -> np.ndarray:
        """ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æç”»ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰"""
        if not result.face_detected or not result.face_landmarks:
            return frame
        
        try:
            # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æç”»
            annotated_frame = frame.copy()
            self.mp_drawing.draw_landmarks(
                annotated_frame,
                result.face_landmarks,
                list(self.mp_face_mesh.FACEMESH_CONTOURS),
                self.mp_drawing_styles.get_default_face_mesh_tesselation_style(),
                self.mp_drawing_styles.get_default_face_mesh_contours_style()
            )
            
            # ä¸­å¿ƒç‚¹æç”»
            if result.face_center:
                height, width = frame.shape[:2]
                center_x = int(result.face_center[0] * width)
                center_y = int(result.face_center[1] * height)
                cv2.circle(annotated_frame, (center_x, center_y), 5, (0, 255, 0), -1)
            
            # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹æç”»
            if result.bounding_box:
                x, y, w, h = result.bounding_box
                cv2.rectangle(annotated_frame, (x, y), (x + w, y + h), (255, 0, 0), 2)
            
            return annotated_frame
            
        except Exception as e:
            self.logger.warning(f"ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æç”»ã‚¨ãƒ©ãƒ¼: {e}")
            return frame
    
    def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾"""
        try:
            if hasattr(self, 'face_mesh'):
                self.face_mesh.close()
            self.logger.info("é¡”æ¤œå‡ºå™¨ãŒã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸ")
        except Exception as e:
            self.logger.warning(f"ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")


# ä½¿ç”¨ä¾‹ã¨ãƒ†ã‚¹ãƒˆ
if __name__ == "__main__":
    import time
    
    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(level=logging.INFO)
    
    # è¨­å®šä¾‹
    config = {
        'face_detection': {
            'max_num_faces': 1,
            'refine_landmarks': True,
            'min_detection_confidence': 0.7,
            'min_tracking_confidence': 0.5
        },
        'adaptive_quality': True
    }
    
    # é¡”æ¤œå‡ºå™¨åˆæœŸåŒ–
    face_detector = FaceDetector(config)
    
    # ã‚«ãƒ¡ãƒ©ã‹ã‚‰ã®ãƒ†ã‚¹ãƒˆï¼ˆã‚«ãƒ¡ãƒ©ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
    try:
        cap = cv2.VideoCapture(0)
        
        if cap.isOpened():
            print("ğŸ”´ ã‚«ãƒ¡ãƒ©ãƒ†ã‚¹ãƒˆé–‹å§‹ï¼ˆQã‚­ãƒ¼ã§çµ‚äº†ï¼‰")
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # é¡”æ¤œå‡º
                result = face_detector.detect_face(frame)
                
                # çµæœè¡¨ç¤º
                if result.face_detected:
                    frame = face_detector.draw_landmarks(frame, result)
                    
                    # æƒ…å ±è¡¨ç¤º
                    info_text = f"Confidence: {result.confidence:.2f}"
                    cv2.putText(frame, info_text, (10, 30), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                
                cv2.imshow('Face Detection Test', frame)
                
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
            
            cap.release()
            cv2.destroyAllWindows()
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆè¡¨ç¤º
            stats = face_detector.get_performance_stats()
            print("\nğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ:")
            for key, value in stats.items():
                print(f"  {key}: {value}")
        
        else:
            print("âŒ ã‚«ãƒ¡ãƒ©ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
    
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    finally:
        face_detector.cleanup()
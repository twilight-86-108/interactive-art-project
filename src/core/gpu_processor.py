# src/core/gpu_processor.py - å®Œå…¨ä¿®æ­£ç‰ˆï¼ˆCUDAç„¡åŠ¹ç’°å¢ƒå¯¾å¿œï¼‰
import cv2
import numpy as np
import logging
from typing import Optional, Tuple, Union
import time

class GPUProcessor:
    """GPUåŠ é€Ÿå‡¦ç†ã‚¯ãƒ©ã‚¹ - CUDAç„¡åŠ¹ç’°å¢ƒã§ã‚‚å‹•ä½œä¿è¨¼"""
    
    def __init__(self):
        self.gpu_available = False
        self.cuda_opencv_available = False
        self.logger = logging.getLogger(__name__)
        
        # CUDAç’°å¢ƒã®è©³ç´°ãƒã‚§ãƒƒã‚¯
        self._check_cuda_environment()
        
        # åˆæœŸåŒ–çµæœã‚’ãƒ­ã‚°å‡ºåŠ›
        self._log_initialization_status()
    
    def _check_cuda_environment(self):
        """CUDAç’°å¢ƒã®åŒ…æ‹¬çš„ãƒã‚§ãƒƒã‚¯"""
        self.cuda_opencv_available = False
        self.gpu_available = False
        
        try:
            # 1. cv2.cuda ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å­˜åœ¨ç¢ºèª
            if not hasattr(cv2, 'cuda'):
                self.logger.warning("OpenCVã«cudaãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
                return
            
            # 2. getCudaEnabledDeviceCounté–¢æ•°ã®å­˜åœ¨ç¢ºèª
            if not hasattr(cv2.cuda, 'getCudaEnabledDeviceCount'):
                self.logger.warning("getCudaEnabledDeviceCounté–¢æ•°ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
                return
            
            # 3. CUDAå¯¾å¿œãƒ‡ãƒã‚¤ã‚¹æ•°ç¢ºèª
            try:
                device_count = cv2.cuda.getCudaEnabledDeviceCount()
                self.logger.info(f"CUDAå¯¾å¿œãƒ‡ãƒã‚¤ã‚¹æ•°: {device_count}")
                
                if device_count == 0:
                    self.logger.warning("CUDAå¯¾å¿œãƒ‡ãƒã‚¤ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆOpenCVãŒCUDAç„¡åŠ¹ã§ãƒ“ãƒ«ãƒ‰ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ï¼‰")
                    return
                
                self.cuda_opencv_available = True
                
            except Exception as e:
                self.logger.warning(f"CUDA ãƒ‡ãƒã‚¤ã‚¹ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
                return
            
            # 4. åŸºæœ¬çš„ãªCUDAæ“ä½œãƒ†ã‚¹ãƒˆ
            try:
                # GpuMatä½œæˆãƒ†ã‚¹ãƒˆ
                test_gpu_mat = cv2.cuda.GpuMat()
                
                # å°ã•ãªãƒ†ã‚¹ãƒˆé…åˆ—ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰/ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ
                test_array = np.zeros((10, 10, 3), dtype=np.uint8)
                test_gpu_mat.upload(test_array)
                result = test_gpu_mat.download()
                
                # åŸºæœ¬çš„ãªCUDAé–¢æ•°ãƒ†ã‚¹ãƒˆ
                if hasattr(cv2.cuda, 'resize') and hasattr(cv2.cuda, 'cvtColor'):
                    self.gpu_available = True
                    self.logger.info("CUDA GPUå‡¦ç†ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
                else:
                    self.logger.warning("å¿…è¦ãªCUDAé–¢æ•°ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
                
            except Exception as e:
                self.logger.warning(f"CUDAåŸºæœ¬æ“ä½œãƒ†ã‚¹ãƒˆã«å¤±æ•—: {e}")
                return
                
        except Exception as e:
            self.logger.warning(f"CUDAç’°å¢ƒç¢ºèªä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _log_initialization_status(self):
        """åˆæœŸåŒ–çŠ¶æ³ã®ãƒ­ã‚°å‡ºåŠ›"""
        if self.gpu_available:
            self.logger.info("âœ… GPUåŠ é€Ÿå‡¦ç†ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
        else:
            self.logger.info("â„¹ï¸ CPUå‡¦ç†ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã—ã¾ã™")
            
            # CUDAç„¡åŠ¹ã®åŸå› ã‚’è©³ã—ãèª¬æ˜
            if not self.cuda_opencv_available:
                self.logger.info("ğŸ’¡ GPUåŠ é€Ÿã‚’æœ‰åŠ¹ã«ã™ã‚‹ã«ã¯ã€CUDAå¯¾å¿œOpenCVã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦ã§ã™")
    
    def gpu_resize(self, frame: np.ndarray, target_size: Tuple[int, int]) -> np.ndarray:
        """GPUåŠ é€Ÿãƒªã‚µã‚¤ã‚ºï¼ˆå®Œå…¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯¾å¿œï¼‰"""
        if not self.gpu_available:
            return self._cpu_resize(frame, target_size)
        
        try:
            # OpenCVã®Pythonãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«ã¯CUDAãƒªã‚µã‚¤ã‚ºAPIãŒå­˜åœ¨ã—ãªã„ãŸã‚ã€CPUã§ãƒªã‚µã‚¤ã‚º
            self.logger.warning("OpenCVã®Pythonãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«ã¯CUDAãƒªã‚µã‚¤ã‚ºAPIãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚CPUãƒªã‚µã‚¤ã‚ºã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚")
            return self._cpu_resize(frame, target_size)
        except Exception as e:
            # GPUå‡¦ç†å¤±æ•—æ™‚ã¯CPUå‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            self.logger.warning(f"GPU ãƒªã‚µã‚¤ã‚ºå¤±æ•—ã€CPUå‡¦ç†ã«åˆ‡æ›¿: {e}")
            self.gpu_available = False  # ä»Šå¾Œã¯CPUå‡¦ç†ã‚’ä½¿ç”¨
            return self._cpu_resize(frame, target_size)
    
    def gpu_color_convert(self, frame: np.ndarray, conversion_code: int) -> np.ndarray:
        """GPUåŠ é€Ÿè‰²ç©ºé–“å¤‰æ›ï¼ˆå®Œå…¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯¾å¿œï¼‰"""
        if not self.gpu_available:
            return self._cpu_color_convert(frame, conversion_code)
        
        try:
            # GPUå‡¦ç†
            gpu_frame = cv2.cuda.GpuMat()
            gpu_frame.upload(frame)
            # OpenCVã®Pythonãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯ cv2.cuda.cvtColor ã¯å­˜åœ¨ã—ãªã„ãŸã‚ã€ä»£ã‚ã‚Šã« cv2.cuda_CvtColor ã‚’ä½¿ç”¨
            self.logger.warning("OpenCVã®Pythonãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«ã¯CUDAè‰²å¤‰æ›APIãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚CPUè‰²å¤‰æ›ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚")
            return self._cpu_color_convert(frame, conversion_code)
        except Exception as e:
            # GPUå‡¦ç†å¤±æ•—æ™‚ã¯CPUå‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            self.logger.warning(f"GPU è‰²å¤‰æ›å¤±æ•—ã€CPUå‡¦ç†ã«åˆ‡æ›¿: {e}")
            self.gpu_available = False  # ä»Šå¾Œã¯CPUå‡¦ç†ã‚’ä½¿ç”¨
            return self._cpu_color_convert(frame, conversion_code)
    
    def process_frame_optimized(self, frame: np.ndarray, 
                              target_size: Optional[Tuple[int, int]] = None,
                              convert_to_rgb: bool = True) -> np.ndarray:
        """æœ€é©åŒ–ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ï¼ˆå¿…ãšæˆåŠŸï¼‰"""
        try:
            # å…¥åŠ›æ¤œè¨¼
            if frame is None or frame.size == 0:
                raise ValueError("ç„¡åŠ¹ãªãƒ•ãƒ¬ãƒ¼ãƒ ãŒå…¥åŠ›ã•ã‚Œã¾ã—ãŸ")
            
            # GPUå‡¦ç†è©¦è¡Œ
            if self.gpu_available:
                try:
                    return self._gpu_process_chain(frame, target_size, convert_to_rgb)
                except Exception as gpu_error:
                    self.logger.warning(f"GPUå‡¦ç†ãƒã‚§ãƒ¼ãƒ³å¤±æ•—: {gpu_error}")
                    self.gpu_available = False  # GPUç„¡åŠ¹åŒ–
            
            # CPUå‡¦ç†ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
            return self._cpu_process_chain(frame, target_size, convert_to_rgb)
            
        except Exception as e:
            self.logger.error(f"ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã§é‡å¤§ã‚¨ãƒ©ãƒ¼: {e}")
            # æœ€ä½é™ã®å‡¦ç†ã§ç¶™ç¶š
            result = frame.copy()
            try:
                if target_size and result.shape[:2] != target_size[::-1]:
                    result = cv2.resize(result, target_size)
                if convert_to_rgb and len(result.shape) == 3 and result.shape[2] == 3:
                    result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)
            except Exception as fallback_error:
                self.logger.error(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚‚å¤±æ•—: {fallback_error}")
                # å…ƒã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãã®ã¾ã¾è¿”ã™
                pass
            
            return result
    
    def _gpu_process_chain(self, frame: np.ndarray,
                          target_size: Optional[Tuple[int, int]],
                          convert_to_rgb: bool) -> np.ndarray:
        """GPUå‡¦ç†ãƒã‚§ãƒ¼ãƒ³"""
        # GPU ãƒ¡ãƒ¢ãƒªã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        gpu_frame = cv2.cuda.GpuMat()
        gpu_frame.upload(frame)
        current_gpu_frame = gpu_frame
        
        # ãƒªã‚µã‚¤ã‚ºå‡¦ç†
        if target_size:
            # OpenCVã®Pythonãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«ã¯CUDAãƒªã‚µã‚¤ã‚ºAPIãŒå­˜åœ¨ã—ãªã„ãŸã‚ã€CPUã§ãƒªã‚µã‚¤ã‚º
            self.logger.warning("OpenCVã®Pythonãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«ã¯CUDAãƒªã‚µã‚¤ã‚ºAPIãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚CPUãƒªã‚µã‚¤ã‚ºã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚")
            result = current_gpu_frame.download()
            result = cv2.resize(result, target_size)
            gpu_frame.upload(result)
            current_gpu_frame = gpu_frame
        
        # è‰²å¤‰æ›å‡¦ç†
        if convert_to_rgb:
            self.logger.warning("OpenCVã®Pythonãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«ã¯CUDAè‰²å¤‰æ›APIãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚CPUè‰²å¤‰æ›ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚")
            result = current_gpu_frame.download()
            result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)
            gpu_frame.upload(result)
            current_gpu_frame = gpu_frame
        
        # çµæœã‚’CPUãƒ¡ãƒ¢ãƒªã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        return current_gpu_frame.download()
    
    def _cpu_process_chain(self, frame: np.ndarray,
                          target_size: Optional[Tuple[int, int]],
                          convert_to_rgb: bool) -> np.ndarray:
        """CPUå‡¦ç†ãƒã‚§ãƒ¼ãƒ³ï¼ˆç¢ºå®Ÿå‹•ä½œï¼‰"""
        result = frame.copy()
        
        # ãƒªã‚µã‚¤ã‚ºå‡¦ç†
        if target_size:
            result = cv2.resize(result, target_size)
        
        # è‰²å¤‰æ›å‡¦ç†
        if convert_to_rgb:
            result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)
        
        return result
    
    # CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
    def _cpu_resize(self, frame: np.ndarray, target_size: Tuple[int, int]) -> np.ndarray:
        """CPU ãƒªã‚µã‚¤ã‚º"""
        return cv2.resize(frame, target_size)
    
    def _cpu_color_convert(self, frame: np.ndarray, conversion_code: int) -> np.ndarray:
        """CPU è‰²å¤‰æ›"""
        return cv2.cvtColor(frame, conversion_code)
    
    def get_system_info(self) -> dict:
        """ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±å–å¾—"""
        info = {
            'gpu_available': self.gpu_available,
            'cuda_opencv_available': self.cuda_opencv_available,
            'opencv_version': cv2.__version__,
            'opencv_cuda_support': hasattr(cv2, 'cuda'),
            'processing_mode': 'GPU' if self.gpu_available else 'CPU'
        }
        
        # CUDAæƒ…å ±ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆã®ã¿ï¼‰
        if self.cuda_opencv_available:
            try:
                info['cuda_device_count'] = cv2.cuda.getCudaEnabledDeviceCount()
                
                # ãƒ‡ãƒã‚¤ã‚¹è©³ç´°æƒ…å ±ï¼ˆã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§ try-catchï¼‰
                try:
                    if info['cuda_device_count'] > 0:
                        # device_info = cv2.cuda.DeviceInfo(0)  # ã“ã‚Œã¯ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹å¯èƒ½æ€§
                        # ã‚ˆã‚Šå®‰å…¨ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
                        info['cuda_functions_available'] = {
                            'resize': hasattr(cv2.cuda, 'resize'),
                            'cvtColor': hasattr(cv2.cuda, 'cvtColor'),
                            'GpuMat': hasattr(cv2.cuda, 'GpuMat')
                        }
                except Exception as device_error:
                    info['device_info_error'] = str(device_error)
                    
            except Exception as cuda_error:
                info['cuda_info_error'] = str(cuda_error)
        
        return info
    
    def benchmark_performance(self, test_size: Tuple[int, int] = (1920, 1080),
                            iterations: int = 50) -> dict:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        results = {
            'test_configuration': {
                'input_size': test_size,
                'output_size': (640, 480),
                'iterations': iterations,
                'operations': ['resize', 'color_convert']
            }
        }
        
        # ãƒ†ã‚¹ãƒˆç”¨ç”»åƒç”Ÿæˆ
        test_image = np.random.randint(0, 255, 
                                     (test_size[1], test_size[0], 3), 
                                     dtype=np.uint8)
        
        # CPUæ€§èƒ½æ¸¬å®š
        self.logger.info("CPUæ€§èƒ½æ¸¬å®šä¸­...")
        cpu_start = time.time()
        for _ in range(iterations):
            result = self._cpu_process_chain(test_image, (640, 480), True)
        cpu_time = time.time() - cpu_start
        
        results['cpu_performance'] = {
            'total_time': cpu_time,
            'fps': iterations / cpu_time,
            'time_per_frame': cpu_time / iterations
        }
        
        # GPUæ€§èƒ½æ¸¬å®šï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
        if self.gpu_available:
            self.logger.info("GPUæ€§èƒ½æ¸¬å®šä¸­...")
            try:
                gpu_start = time.time()
                for _ in range(iterations):
                    result = self._gpu_process_chain(test_image, (640, 480), True)
                gpu_time = time.time() - gpu_start
                
                results['gpu_performance'] = {
                    'total_time': gpu_time,
                    'fps': iterations / gpu_time,
                    'time_per_frame': gpu_time / iterations,
                    'speedup_factor': cpu_time / gpu_time
                }
                
            except Exception as gpu_bench_error:
                results['gpu_benchmark_error'] = {"error": str(gpu_bench_error)}
        else:
            results['gpu_performance'] = {"error": "GPUå‡¦ç†ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"}
        
        return results
    
    def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾"""
        try:
            if self.gpu_available:
                # CUDAé–¢é€£ãƒªã‚½ãƒ¼ã‚¹ã®è§£æ”¾ã‚’è©¦è¡Œ
                try:
                    cv2.cuda.resetDevice()
                    self.logger.info("CUDAãƒ‡ãƒã‚¤ã‚¹ãƒªã‚»ãƒƒãƒˆå®Œäº†")
                except Exception as reset_error:
                    self.logger.warning(f"CUDAãƒ‡ãƒã‚¤ã‚¹ãƒªã‚»ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {reset_error}")
            
            self.gpu_available = False
            self.cuda_opencv_available = False
            self.logger.info("GPU ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
            
        except Exception as cleanup_error:
            self.logger.warning(f"ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {cleanup_error}")


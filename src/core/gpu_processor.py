# src/core/gpu_processor.py - çµ±åˆå®Œå…¨ç‰ˆ
import cv2
import ctypes
import numpy as np
import logging
import time
from typing import Optional, Tuple, Union
from pathlib import Path
from enum import Enum

class GPUBackend(Enum):
    """GPUå‡¦ç†ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚¿ã‚¤ãƒ—"""
    CUSTOM_CPP = "custom_cpp"          # ã‚«ã‚¹ã‚¿ãƒ C++ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
    OPENCV_CUDA = "opencv_cuda"        # OpenCV CUDA
    CPU_FALLBACK = "cpu_fallback"      # CPUå‡¦ç†

class GPUProcessor:
    """
    çµ±åˆGPUåŠ é€Ÿå‡¦ç†ã‚¯ãƒ©ã‚¹
    
    å‡¦ç†å„ªå…ˆé †ä½:
    1. ã‚«ã‚¹ã‚¿ãƒ C++ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆæœ€é«˜æ€§èƒ½ï¼‰
    2. OpenCV CUDAï¼ˆæ¨™æº–GPUå‡¦ç†ï¼‰
    3. CPUå‡¦ç†ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # åˆ©ç”¨å¯èƒ½ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰
        self.available_backends = []
        self.current_backend = GPUBackend.CPU_FALLBACK
        
        # C++ãƒ©ã‚¤ãƒ–ãƒ©ãƒªé–¢é€£
        self.cpp_lib = None
        self.cpp_available = False
        
        # OpenCV CUDAé–¢é€£
        self.opencv_cuda_available = False
        
        # çµ±è¨ˆæƒ…å ±
        self.processing_stats = {
            'total_frames': 0,
            'gpu_frames': 0,
            'cpu_frames': 0,
            'avg_processing_time': 0.0,
            'backend_switches': 0
        }
        
        # åˆæœŸåŒ–å®Ÿè¡Œ
        self._initialize_backends()
        self._select_optimal_backend()
        self._log_initialization_status()
    
    def _initialize_backends(self):
        """åˆ©ç”¨å¯èƒ½ãªãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’åˆæœŸåŒ–"""
        
        # 1. ã‚«ã‚¹ã‚¿ãƒ C++ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®åˆæœŸåŒ–è©¦è¡Œ
        self._init_cpp_backend()
        
        # 2. OpenCV CUDA ã®åˆæœŸåŒ–è©¦è¡Œ
        self._init_opencv_cuda_backend()
        
        # 3. CPUå‡¦ç†ã¯å¸¸ã«åˆ©ç”¨å¯èƒ½
        self.available_backends.append(GPUBackend.CPU_FALLBACK)
    
    def _init_cpp_backend(self):
        """ã‚«ã‚¹ã‚¿ãƒ C++ãƒ©ã‚¤ãƒ–ãƒ©ãƒªåˆæœŸåŒ–"""
        try:
            # ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ‘ã‚¹å€™è£œ
            lib_paths = [
                Path(__file__).parent.parent.parent / "cpp" / "build" / "libaqua_mirror_gpu.so",
                Path(__file__).parent.parent.parent / "cpp" / "build" / "libaqua_mirror_gpu.dll",
                Path("./cpp/build/libaqua_mirror_gpu.so"),
                Path("./libaqua_mirror_gpu.so")
            ]
            
            for lib_path in lib_paths:
                if lib_path.exists():
                    self.cpp_lib = ctypes.CDLL(str(lib_path))
                    self._setup_cpp_function_signatures()
                    
                    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
                    if self._test_cpp_library():
                        self.cpp_available = True
                        self.available_backends.append(GPUBackend.CUSTOM_CPP)
                        self.logger.info(f"âœ… ã‚«ã‚¹ã‚¿ãƒ C++ãƒ©ã‚¤ãƒ–ãƒ©ãƒªåˆæœŸåŒ–æˆåŠŸ: {lib_path}")
                        break
                    
        except Exception as e:
            self.logger.warning(f"ã‚«ã‚¹ã‚¿ãƒ C++ãƒ©ã‚¤ãƒ–ãƒ©ãƒªåˆæœŸåŒ–å¤±æ•—: {e}")
    
    def _setup_cpp_function_signatures(self):
        """C++é–¢æ•°ã‚·ã‚°ãƒãƒãƒ£è¨­å®š"""
        if not self.cpp_lib:
            return
        try:
            # resize_gpué–¢æ•°
            self.cpp_lib.resize_gpu.argtypes = [
                ctypes.POINTER(ctypes.c_ubyte),  # input
                ctypes.POINTER(ctypes.c_ubyte),  # output
                ctypes.c_int,                    # input_width
                ctypes.c_int,                    # input_height
                ctypes.c_int,                    # output_width
                ctypes.c_int,                    # output_height
                ctypes.c_int                     # channels
            ]
            self.cpp_lib.resize_gpu.restype = ctypes.c_int
            
            # color_convert_gpué–¢æ•°
            self.cpp_lib.color_convert_gpu.argtypes = [
                ctypes.POINTER(ctypes.c_ubyte),  # input
                ctypes.POINTER(ctypes.c_ubyte),  # output
                ctypes.c_int,                    # width
                ctypes.c_int,                    # height
                ctypes.c_int                     # conversion_code
            ]
            self.cpp_lib.color_convert_gpu.restype = ctypes.c_int
            
            # ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±é–¢æ•°
            if hasattr(self.cpp_lib, 'get_gpu_info'):
                self.cpp_lib.get_gpu_info.argtypes = []
                self.cpp_lib.get_gpu_info.restype = ctypes.c_int
                
        except Exception as e:
            self.logger.error(f"C++é–¢æ•°ã‚·ã‚°ãƒãƒãƒ£è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _test_cpp_library(self) -> bool:
        """C++ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ†ã‚¹ãƒˆ"""
        if not self.cpp_lib:
            return False
        try:
            # å°ã•ãªãƒ†ã‚¹ãƒˆç”»åƒã§ãƒªã‚µã‚¤ã‚ºãƒ†ã‚¹ãƒˆ
            test_input = np.random.randint(0, 255, (100, 100, 3), dtype=np.uint8)
            test_output = np.zeros((50, 50, 3), dtype=np.uint8)
            
            input_ptr = test_input.ctypes.data_as(ctypes.POINTER(ctypes.c_ubyte))
            output_ptr = test_output.ctypes.data_as(ctypes.POINTER(ctypes.c_ubyte))
            
            result = self.cpp_lib.resize_gpu(input_ptr, output_ptr, 100, 100, 50, 50, 3)
            
            return result == 0  # æˆåŠŸã‚³ãƒ¼ãƒ‰
            
        except Exception as e:
            self.logger.warning(f"C++ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
            return False
    
    def _init_opencv_cuda_backend(self):
        """OpenCV CUDAåˆæœŸåŒ–"""
        try:
            # OpenCV CUDA ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å­˜åœ¨ç¢ºèª
            if not hasattr(cv2, 'cuda'):
                self.logger.warning("OpenCVã«CUDAãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
                return
            
            if not hasattr(cv2.cuda, 'getCudaEnabledDeviceCount'):
                self.logger.warning("getCudaEnabledDeviceCounté–¢æ•°ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
                return
            
            # CUDAå¯¾å¿œãƒ‡ãƒã‚¤ã‚¹ç¢ºèª
            device_count = cv2.cuda.getCudaEnabledDeviceCount()
            if device_count == 0:
                self.logger.warning("CUDAå¯¾å¿œãƒ‡ãƒã‚¤ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return
            
            # åŸºæœ¬çš„ãªCUDAæ“ä½œãƒ†ã‚¹ãƒˆ
            test_gpu_mat = cv2.cuda.GpuMat()
            test_array = np.zeros((10, 10, 3), dtype=np.uint8)
            test_gpu_mat.upload(test_array)
            test_gpu_mat.download()
            
            self.opencv_cuda_available = True
            self.available_backends.append(GPUBackend.OPENCV_CUDA)
            self.logger.info(f"âœ… OpenCV CUDAåˆæœŸåŒ–æˆåŠŸ (ãƒ‡ãƒã‚¤ã‚¹æ•°: {device_count})")
            
        except Exception as e:
            self.logger.warning(f"OpenCV CUDAåˆæœŸåŒ–å¤±æ•—: {e}")
    
    def _select_optimal_backend(self):
        """æœ€é©ãªãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’é¸æŠ"""
        if GPUBackend.CUSTOM_CPP in self.available_backends:
            self.current_backend = GPUBackend.CUSTOM_CPP
        elif GPUBackend.OPENCV_CUDA in self.available_backends:
            self.current_backend = GPUBackend.OPENCV_CUDA
        else:
            self.current_backend = GPUBackend.CPU_FALLBACK
    
    def _log_initialization_status(self):
        """åˆæœŸåŒ–çŠ¶æ³ãƒ­ã‚°å‡ºåŠ›"""
        self.logger.info(f"ğŸ”§ åˆ©ç”¨å¯èƒ½ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰: {[b.value for b in self.available_backends]}")
        self.logger.info(f"ğŸ¯ é¸æŠã•ã‚ŒãŸãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰: {self.current_backend.value}")
        
        if self.current_backend == GPUBackend.CPU_FALLBACK:
            self.logger.info("ğŸ’¡ GPUåŠ é€Ÿã‚’æœ‰åŠ¹ã«ã™ã‚‹ã«ã¯:")
            self.logger.info("   1. ã‚«ã‚¹ã‚¿ãƒ C++ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒ“ãƒ«ãƒ‰")
            self.logger.info("   2. CUDAå¯¾å¿œOpenCVã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")
    
    def resize_frame(self, frame: np.ndarray, target_size: Tuple[int, int]) -> np.ndarray:
        """çµ±åˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒªã‚µã‚¤ã‚º"""
        start_time = time.time()
        
        try:
            # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰åˆ¥å‡¦ç†
            if self.current_backend == GPUBackend.CUSTOM_CPP:
                result = self._cpp_resize(frame, target_size)
            elif self.current_backend == GPUBackend.OPENCV_CUDA:
                result = self._opencv_cuda_resize(frame, target_size)
            else:
                result = self._cpu_resize(frame, target_size)
            
            # çµ±è¨ˆæ›´æ–°
            processing_time = time.time() - start_time
            self._update_stats(processing_time, self.current_backend != GPUBackend.CPU_FALLBACK)
            
            return result
            
        except Exception as e:
            self.logger.warning(f"ãƒªã‚µã‚¤ã‚ºå‡¦ç†ã‚¨ãƒ©ãƒ¼ ({self.current_backend.value}): {e}")
            return self._fallback_resize(frame, target_size, e)
    
    def color_convert(self, frame: np.ndarray, conversion_code: int) -> np.ndarray:
        """çµ±åˆè‰²ç©ºé–“å¤‰æ›"""
        start_time = time.time()
        
        try:
            # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰åˆ¥å‡¦ç†
            if self.current_backend == GPUBackend.CUSTOM_CPP:
                result = self._cpp_color_convert(frame, conversion_code)
            elif self.current_backend == GPUBackend.OPENCV_CUDA:
                result = self._opencv_cuda_color_convert(frame, conversion_code)
            else:
                result = self._cpu_color_convert(frame, conversion_code)
            
            # çµ±è¨ˆæ›´æ–°
            processing_time = time.time() - start_time
            self._update_stats(processing_time, self.current_backend != GPUBackend.CPU_FALLBACK)
            
            return result
            
        except Exception as e:
            self.logger.warning(f"è‰²å¤‰æ›å‡¦ç†ã‚¨ãƒ©ãƒ¼ ({self.current_backend.value}): {e}")
            return self._fallback_color_convert(frame, conversion_code, e)
    
    def process_frame_optimized(self, frame: np.ndarray,
                              target_size: Optional[Tuple[int, int]] = None,
                              convert_to_rgb: bool = True) -> np.ndarray:
        """æœ€é©åŒ–çµ±åˆãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†"""
        if frame is None or frame.size == 0:
            raise ValueError("ç„¡åŠ¹ãªãƒ•ãƒ¬ãƒ¼ãƒ ãŒå…¥åŠ›ã•ã‚Œã¾ã—ãŸ")
        
        result = frame.copy()
        
        try:
            # ãƒªã‚µã‚¤ã‚ºå‡¦ç†
            if target_size and result.shape[:2] != target_size[::-1]:
                result = self.resize_frame(result, target_size)
            
            # è‰²å¤‰æ›å‡¦ç†
            if convert_to_rgb and len(result.shape) == 3 and result.shape[2] == 3:
                result = self.color_convert(result, cv2.COLOR_BGR2RGB)
            
            return result
            
        except Exception as e:
            self.logger.error(f"çµ±åˆãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã§é‡å¤§ã‚¨ãƒ©ãƒ¼: {e}")
            # æœ€ä½é™ã®å‡¦ç†ã§ç¶™ç¶š
            try:
                if target_size:
                    result = cv2.resize(result, target_size)
                if convert_to_rgb:
                    result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)
            except:
                pass  # å…ƒã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¿”ã™
            
            return result
    
    # =====================================================
    # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰åˆ¥å®Ÿè£…
    # =====================================================
    
    def _cpp_resize(self, frame: np.ndarray, target_size: Tuple[int, int]) -> np.ndarray:
        """ã‚«ã‚¹ã‚¿ãƒ C++ãƒªã‚µã‚¤ã‚º"""
        if not self.cpp_lib:
            raise RuntimeError("ã‚«ã‚¹ã‚¿ãƒ C++ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        h, w, c = frame.shape
        target_w, target_h = target_size
        
        # å‡ºåŠ›é…åˆ—æº–å‚™
        output = np.zeros((target_h, target_w, c), dtype=np.uint8)
        
        # GPUå‡¦ç†å®Ÿè¡Œ
        input_ptr = frame.ctypes.data_as(ctypes.POINTER(ctypes.c_ubyte))
        output_ptr = output.ctypes.data_as(ctypes.POINTER(ctypes.c_ubyte))
        
        result_code = self.cpp_lib.resize_gpu(input_ptr, output_ptr, w, h, target_w, target_h, c)
        
        if result_code != 0:
            raise RuntimeError(f"C++ãƒªã‚µã‚¤ã‚ºå‡¦ç†å¤±æ•— (ã‚³ãƒ¼ãƒ‰: {result_code})")
        
        return output
    
    def _cpp_color_convert(self, frame: np.ndarray, conversion_code: int) -> np.ndarray:
        """ã‚«ã‚¹ã‚¿ãƒ C++è‰²å¤‰æ›"""
        if not self.cpp_lib:
            raise RuntimeError("ã‚«ã‚¹ã‚¿ãƒ C++ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        h, w, c = frame.shape
        output_channels = 3 if conversion_code == cv2.COLOR_BGR2RGB else c
        
        # å‡ºåŠ›é…åˆ—æº–å‚™
        output = np.zeros((h, w, output_channels), dtype=np.uint8)
        
        # GPUå‡¦ç†å®Ÿè¡Œ
        input_ptr = frame.ctypes.data_as(ctypes.POINTER(ctypes.c_ubyte))
        output_ptr = output.ctypes.data_as(ctypes.POINTER(ctypes.c_ubyte))
        
        result_code = self.cpp_lib.color_convert_gpu(input_ptr, output_ptr, w, h, conversion_code)
        
        if result_code != 0:
            raise RuntimeError(f"C++è‰²å¤‰æ›å‡¦ç†å¤±æ•— (ã‚³ãƒ¼ãƒ‰: {result_code})")
        
        return output
    
    def _opencv_cuda_resize(self, frame: np.ndarray, target_size: Tuple[int, int]) -> np.ndarray:
        """OpenCV CUDAãƒªã‚µã‚¤ã‚º"""
        # æ³¨æ„: OpenCVã®Pythonãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯ç›´æ¥çš„ãªCUDAãƒªã‚µã‚¤ã‚ºAPIãŒãªã„å ´åˆãŒã‚ã‚‹
        # ã“ã®å®Ÿè£…ã¯æ¦‚å¿µçš„ãªã‚‚ã®ã§ã€å®Ÿéš›ã®APIã«åˆã‚ã›ã¦èª¿æ•´ãŒå¿…è¦
        gpu_frame = cv2.cuda.GpuMat()
        gpu_frame.upload(frame)
        
        # GPUä¸Šã§ãƒªã‚µã‚¤ã‚ºï¼ˆAPIç¢ºèªè¦ï¼‰
        # gpu_resized = cv2.cuda.resize(gpu_frame, target_size)
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: CPUãƒªã‚µã‚¤ã‚º
        cpu_frame = gpu_frame.download()
        resized = cv2.resize(cpu_frame, target_size)
        
        return resized
    
    def _opencv_cuda_color_convert(self, frame: np.ndarray, conversion_code: int) -> np.ndarray:
        """OpenCV CUDAè‰²å¤‰æ›"""
        gpu_frame = cv2.cuda.GpuMat()
        gpu_frame.upload(frame)
        
        # GPUä¸Šã§è‰²å¤‰æ›ï¼ˆAPIç¢ºèªè¦ï¼‰
        # gpu_converted = cv2.cuda.cvtColor(gpu_frame, conversion_code)
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: CPUè‰²å¤‰æ›
        cpu_frame = gpu_frame.download()
        converted = cv2.cvtColor(cpu_frame, conversion_code)
        
        return converted
    
    def _cpu_resize(self, frame: np.ndarray, target_size: Tuple[int, int]) -> np.ndarray:
        """CPU ãƒªã‚µã‚¤ã‚º"""
        return cv2.resize(frame, target_size)
    
    def _cpu_color_convert(self, frame: np.ndarray, conversion_code: int) -> np.ndarray:
        """CPU è‰²å¤‰æ›"""
        return cv2.cvtColor(frame, conversion_code)
    
    # =====================================================
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ»ã‚¨ãƒ©ãƒ¼å‡¦ç†
    # =====================================================
    
    def _fallback_resize(self, frame: np.ndarray, target_size: Tuple[int, int], error: Exception) -> np.ndarray:
        """ãƒªã‚µã‚¤ã‚ºãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†"""
        self._handle_backend_error(error)
        return self._cpu_resize(frame, target_size)
    
    def _fallback_color_convert(self, frame: np.ndarray, conversion_code: int, error: Exception) -> np.ndarray:
        """è‰²å¤‰æ›ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†"""
        self._handle_backend_error(error)
        return self._cpu_color_convert(frame, conversion_code)
    
    def _handle_backend_error(self, error: Exception):
        """ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚¨ãƒ©ãƒ¼å‡¦ç†"""
        # ç¾åœ¨ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’ç„¡åŠ¹åŒ–
        if self.current_backend in self.available_backends:
            self.available_backends.remove(self.current_backend)
            self.processing_stats['backend_switches'] += 1
        
        # æ¬¡ã®åˆ©ç”¨å¯èƒ½ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«åˆ‡æ›¿
        self._select_optimal_backend()
        
        self.logger.warning(f"ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰åˆ‡æ›¿: {self.current_backend.value}")
    
    # =====================================================
    # çµ±è¨ˆãƒ»ç›£è¦–æ©Ÿèƒ½
    # =====================================================
    
    def _update_stats(self, processing_time: float, is_gpu: bool):
        """çµ±è¨ˆæƒ…å ±æ›´æ–°"""
        self.processing_stats['total_frames'] += 1
        
        if is_gpu:
            self.processing_stats['gpu_frames'] += 1
        else:
            self.processing_stats['cpu_frames'] += 1
        
        # ç§»å‹•å¹³å‡ã§å‡¦ç†æ™‚é–“æ›´æ–°
        alpha = 0.1
        self.processing_stats['avg_processing_time'] = (
            alpha * processing_time + 
            (1 - alpha) * self.processing_stats['avg_processing_time']
        )
    
    def get_system_info(self) -> dict:
        """ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±å–å¾—"""
        info = {
            'current_backend': self.current_backend.value,
            'available_backends': [b.value for b in self.available_backends],
            'cpp_library_available': self.cpp_available,
            'opencv_cuda_available': self.opencv_cuda_available,
            'opencv_version': cv2.__version__,
            'processing_stats': self.processing_stats.copy()
        }
        
        # CUDAè©³ç´°æƒ…å ±
        if self.opencv_cuda_available:
            try:
                info['cuda_device_count'] = cv2.cuda.getCudaEnabledDeviceCount()
            except:
                info['cuda_device_count'] = 0
        
        return info
    
    def benchmark_performance(self, test_size: Tuple[int, int] = (1920, 1080),
                            iterations: int = 50) -> dict:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        results = {
            'test_configuration': {
                'input_size': test_size,
                'output_size': (640, 480),
                'iterations': iterations
            },
            'backend_performance': {}
        }
        
        # ãƒ†ã‚¹ãƒˆç”¨ç”»åƒ
        test_image = np.random.randint(0, 255, (test_size[1], test_size[0], 3), dtype=np.uint8)
        
        # å„ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
        for backend in self.available_backends:
            original_backend = self.current_backend
            self.current_backend = backend
            
            try:
                self.logger.info(f"ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œä¸­: {backend.value}")
                
                start_time = time.time()
                for _ in range(iterations):
                    result = self.process_frame_optimized(test_image, (640, 480), True)
                total_time = time.time() - start_time
                
                results['backend_performance'][backend.value] = {
                    'total_time': total_time,
                    'fps': iterations / total_time,
                    'time_per_frame': total_time / iterations
                }
                
            except Exception as e:
                results['backend_performance'][backend.value] = {
                    'error': str(e)
                }
            
            finally:
                self.current_backend = original_backend
        
        return results
    
    def is_gpu_available(self) -> bool:
        """GPUå‡¦ç†åˆ©ç”¨å¯èƒ½æ€§"""
        return self.current_backend in [GPUBackend.CUSTOM_CPP, GPUBackend.OPENCV_CUDA]
    
    def force_backend(self, backend: GPUBackend) -> bool:
        """ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å¼·åˆ¶åˆ‡æ›¿"""
        if backend in self.available_backends:
            self.current_backend = backend
            self.logger.info(f"ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å¼·åˆ¶åˆ‡æ›¿: {backend.value}")
            return True
        else:
            self.logger.warning(f"ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ {backend.value} ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“")
            return False
    
    def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾"""
        try:
            # CUDAé–¢é€£ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾
            if self.opencv_cuda_available:
                try:
                    cv2.cuda.resetDevice()
                except:
                    pass
            
            # C++ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒªã‚½ãƒ¼ã‚¹è§£æ”¾
            if self.cpp_available and self.cpp_lib:
                try:
                    if hasattr(self.cpp_lib, 'cleanup_gpu'):
                        self.cpp_lib.cleanup_gpu()
                except:
                    pass
            
            self.logger.info("GPU ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
            
        except Exception as e:
            self.logger.warning(f"ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
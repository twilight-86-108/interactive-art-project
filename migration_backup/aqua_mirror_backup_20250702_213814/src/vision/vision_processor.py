# src/vision/vision_processor.py - æœ€çµ‚çµ±åˆç‰ˆ
import cv2
import numpy as np
import time
import logging
import threading
from typing import Optional, Dict, Any, Tuple, List
from collections import deque
from enum import Enum
from concurrent.futures import ThreadPoolExecutor
import gc

class VisionBackend(Enum):
    """Visionå‡¦ç†ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚¿ã‚¤ãƒ—"""
    MODULAR_GPU = "modular_gpu"          # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†é›¢ + GPUæœ€é©åŒ–
    MODULAR_CPU = "modular_cpu"          # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†é›¢ + CPUå‡¦ç†
    MEDIAPIPE_DIRECT = "mediapipe_direct" # MediaPipeç›´æ¥å‡¦ç†
    FALLBACK = "fallback"                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

class PerformanceLevel(Enum):
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«"""
    ULTRA = "ultra"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    MINIMAL = "minimal"

class VisionProcessor:
    """
    æœ€çµ‚çµ±åˆã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³å‡¦ç†ã‚¯ãƒ©ã‚¹
    
    ç‰¹å¾´:
    - ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†é›¢è¨­è¨ˆ + è¤‡æ•°ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å¯¾å¿œ
    - è©³ç´°ãªçµæœçµ±åˆãƒ»ç›¸äº’ä½œç”¨åˆ†æ
    - é©å¿œçš„å“è³ªåˆ¶å¾¡ãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
    - å …ç‰¢ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ»è‡ªå‹•å¾©æ—§
    """
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = self._setup_logger()
        
        # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ç®¡ç†
        self.available_backends: List[VisionBackend] = []
        self.current_backend = VisionBackend.FALLBACK
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç®¡ç†
        self.target_fps = config.get('performance', {}).get('target_fps', 30)
        self.performance_level = PerformanceLevel.HIGH
        self.adaptive_quality = config.get('adaptive_quality', True)
        
        # å‡¦ç†çµ±è¨ˆ
        self.processing_times = deque(maxlen=60)
        self.frame_count = 0
        self.last_fps_time = time.time()
        self.current_fps = 0.0
        self.frame_skip = 0
        
        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆå‚ç…§
        self.face_detector = None
        self.hand_detector = None
        self.gpu_processor = None
        self.camera = None
        
        # MediaPipeç›´æ¥å‡¦ç†ç”¨
        self.face_mesh = None
        self.hands = None
        self.mp_face_mesh = None
        self.mp_hands = None
        
        # ä¸¦åˆ—å‡¦ç†
        self.executor = ThreadPoolExecutor(max_workers=3, thread_name_prefix="Vision")
        
        # å“è³ªåˆ¶å¾¡è¨­å®š
        self.quality_configs = self._init_quality_configs()
        self._quality_settings: Dict[str, Any] = {}
        
        # çµæœç®¡ç†
        self.last_detection_result = self._create_default_result()
        
        # çµ±è¨ˆæƒ…å ±
        self.stats = {
            'total_frames': 0,
            'successful_frames': 0,
            'failed_frames': 0,
            'backend_switches': 0,
            'avg_processing_time': 0.0,
            'interaction_detections': 0,
            'gesture_detections': 0
        }
        
        # åˆæœŸåŒ–å®Ÿè¡Œ
        self._initialize_system()
    
    def _setup_logger(self) -> logging.Logger:
        """ãƒ­ã‚¬ãƒ¼è¨­å®š"""
        logger = logging.getLogger(f"{__name__}.VisionProcessor")
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
        return logger
    
    def _init_quality_configs(self) -> Dict[PerformanceLevel, Dict[str, Any]]:
        """å“è³ªãƒ¬ãƒ™ãƒ«åˆ¥è¨­å®š"""
        return {
            PerformanceLevel.ULTRA: {
                'resolution': (1280, 720),
                'model_complexity': 2,
                'refine_landmarks': True,
                'min_detection_confidence': 0.8,
                'min_tracking_confidence': 0.7,
                'max_num_faces': 2,
                'max_num_hands': 2,
                'frame_skip_max': 0,
                'gpu_optimization': True
            },
            PerformanceLevel.HIGH: {
                'resolution': (960, 540),
                'model_complexity': 1,
                'refine_landmarks': True,
                'min_detection_confidence': 0.7,
                'min_tracking_confidence': 0.6,
                'max_num_faces': 1,
                'max_num_hands': 2,
                'frame_skip_max': 1,
                'gpu_optimization': True
            },
            PerformanceLevel.MEDIUM: {
                'resolution': (640, 480),
                'model_complexity': 1,
                'refine_landmarks': False,
                'min_detection_confidence': 0.6,
                'min_tracking_confidence': 0.5,
                'max_num_faces': 1,
                'max_num_hands': 2,
                'frame_skip_max': 2,
                'gpu_optimization': True
            },
            PerformanceLevel.LOW: {
                'resolution': (480, 360),
                'model_complexity': 0,
                'refine_landmarks': False,
                'min_detection_confidence': 0.5,
                'min_tracking_confidence': 0.4,
                'max_num_faces': 1,
                'max_num_hands': 1,
                'frame_skip_max': 3,
                'gpu_optimization': False
            },
            PerformanceLevel.MINIMAL: {
                'resolution': (320, 240),
                'model_complexity': 0,
                'refine_landmarks': False,
                'min_detection_confidence': 0.4,
                'min_tracking_confidence': 0.3,
                'max_num_faces': 1,
                'max_num_hands': 1,
                'frame_skip_max': 4,
                'gpu_optimization': False
            }
        }
    
    def _create_default_result(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆçµæœä½œæˆ"""
        return {
            # åŸºæœ¬æƒ…å ±
            'timestamp': time.time(),
            'frame_shape': (480, 640, 3),
            'processing_backend': 'unknown',
            'processing_time': 0.0,
            'performance_level': self.performance_level.value,
            
            # é¡”æ¤œå‡ºçµæœ
            'face_detected': False,
            'face_landmarks': None,
            'face_center': None,
            'face_distance': float('inf'),
            'face_rotation': {},
            'face_bbox': (0, 0, 0, 0),
            'face_count': 0,
            
            # æ‰‹æ¤œå‡ºçµæœ
            'hands_detected': False,
            'hand_landmarks': None,
            'hand_positions': [],
            'hand_count': 0,
            'hands_info': [],
            'hand_gestures': [],
            
            # ç›¸äº’ä½œç”¨æƒ…å ±
            'interaction_data': {},
            'confidence_scores': {},
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±
            'fps_estimate': 0.0,
            'gpu_acceleration': False
        }
    
    def _initialize_system(self):
        """ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        self.logger.info("ğŸš€ æœ€çµ‚çµ±åˆVisionProcessor ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–é–‹å§‹...")
        
        # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ç™ºè¦‹ãƒ»åˆæœŸåŒ–
        self._discover_and_init_backends()
        
        # æœ€é©ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰é¸æŠ
        self._select_optimal_backend()
        
        # ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–
        self._init_camera()
        
        # åˆæœŸåŒ–å®Œäº†ãƒ­ã‚°
        self._log_initialization_summary()
    
    def _discover_and_init_backends(self):
        """ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ç™ºè¦‹ãƒ»åˆæœŸåŒ–"""
        # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†é›¢GPUæœ€é©åŒ–ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰
        if self._init_modular_gpu_backend():
            self.available_backends.append(VisionBackend.MODULAR_GPU)
        
        # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†é›¢CPUå‡¦ç†ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰
        if self._init_modular_cpu_backend():
            self.available_backends.append(VisionBackend.MODULAR_CPU)
        
        # MediaPipeç›´æ¥å‡¦ç†ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰
        if self._init_mediapipe_direct_backend():
            self.available_backends.append(VisionBackend.MEDIAPIPE_DIRECT)
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆå¸¸ã«åˆ©ç”¨å¯èƒ½ï¼‰
        self.available_backends.append(VisionBackend.FALLBACK)
        
        self.logger.info(f"ğŸ“‹ åˆ©ç”¨å¯èƒ½ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰: {[b.value for b in self.available_backends]}")
    
    def _init_modular_gpu_backend(self) -> bool:
        """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†é›¢GPUæœ€é©åŒ–ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰åˆæœŸåŒ–"""
        try:
            # GPU ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼åˆæœŸåŒ–
            from ..core.gpu_processor import GPUProcessor
            self.gpu_processor = GPUProcessor()
            
            if not self.gpu_processor.get_system_info().get('gpu_available', False):
                return False
            
            # å€‹åˆ¥æ¤œå‡ºå™¨åˆæœŸåŒ–
            from .face_detector import FaceDetector
            from .hand_detector import HandDetector
            
            # å“è³ªè¨­å®šã§ã‚³ãƒ³ãƒ•ã‚£ã‚°æ›´æ–°
            quality_config = self.quality_configs[self.performance_level]
            enhanced_config = self.config.copy()
            enhanced_config.update(quality_config)
            
            self.face_detector = FaceDetector(enhanced_config)
            self.hand_detector = HandDetector(enhanced_config)
            
            self.logger.info("âœ… ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†é›¢GPUæœ€é©åŒ–ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰åˆæœŸåŒ–å®Œäº†")
            return True
            
        except (ImportError, Exception) as e:
            self.logger.debug(f"ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†é›¢GPUæœ€é©åŒ–ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰åˆæœŸåŒ–å¤±æ•—: {e}")
            return False
    
    def _init_modular_cpu_backend(self) -> bool:
        """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†é›¢CPUå‡¦ç†ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰åˆæœŸåŒ–"""
        try:
            # å€‹åˆ¥æ¤œå‡ºå™¨åˆæœŸåŒ–ï¼ˆCPUãƒ¢ãƒ¼ãƒ‰ï¼‰
            from .face_detector import FaceDetector
            from .hand_detector import HandDetector
            
            # CPUæœ€é©åŒ–è¨­å®š
            quality_config = self.quality_configs[self.performance_level]
            cpu_config = self.config.copy()
            cpu_config.update(quality_config)
            cpu_config['gpu_optimization'] = False
            
            # GPU ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã¯ä½¿ç”¨ã—ãªã„ï¼ˆCPUç‰ˆã§ã¯ï¼‰
            test_face_detector = FaceDetector(cpu_config)
            test_hand_detector = HandDetector(cpu_config)
            
            # åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
            if (hasattr(test_face_detector, 'detect_face') and 
                hasattr(test_hand_detector, 'detect_hands')):
                
                self.logger.info("âœ… ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†é›¢CPUå‡¦ç†ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰åˆ©ç”¨å¯èƒ½")
                return True
            
            return False
            
        except (ImportError, Exception) as e:
            self.logger.debug(f"ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†é›¢CPUå‡¦ç†ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰åˆæœŸåŒ–å¤±æ•—: {e}")
            return False
    
    def _init_mediapipe_direct_backend(self) -> bool:
        """MediaPipeç›´æ¥å‡¦ç†ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰åˆæœŸåŒ–"""
        try:
            import mediapipe as mp
            
            self.mp_face_mesh = mp.solutions.face_mesh
            self.mp_hands = mp.solutions.hands
            
            # ãƒ†ã‚¹ãƒˆç”¨åˆæœŸåŒ–
            test_face_mesh = self.mp_face_mesh.FaceMesh(
                static_image_mode=False,
                max_num_faces=1,
                refine_landmarks=False,
                min_detection_confidence=0.5
            )
            test_hands = self.mp_hands.Hands(
                static_image_mode=False,
                max_num_hands=2,
                min_detection_confidence=0.5
            )
            
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            test_face_mesh.close()
            test_hands.close()
            
            self.logger.info("âœ… MediaPipeç›´æ¥å‡¦ç†ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰åˆ©ç”¨å¯èƒ½")
            return True
            
        except Exception as e:
            self.logger.debug(f"MediaPipeç›´æ¥å‡¦ç†ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰åˆæœŸåŒ–å¤±æ•—: {e}")
            return False
    
    def _select_optimal_backend(self):
        """æœ€é©ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰é¸æŠ"""
        # å„ªå…ˆé †ä½
        priority = [
            VisionBackend.MODULAR_GPU,
            VisionBackend.MODULAR_CPU,
            VisionBackend.MEDIAPIPE_DIRECT,
            VisionBackend.FALLBACK
        ]
        
        for backend in priority:
            if backend in self.available_backends:
                self.current_backend = backend
                break
        
        # é¸æŠã•ã‚ŒãŸãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰åˆæœŸåŒ–
        self._initialize_current_backend()
    
    def _initialize_current_backend(self):
        """ç¾åœ¨ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰åˆæœŸåŒ–"""
        try:
            if self.current_backend == VisionBackend.MODULAR_GPU:
                self._init_modular_gpu_components()
            elif self.current_backend == VisionBackend.MODULAR_CPU:
                self._init_modular_cpu_components()
            elif self.current_backend == VisionBackend.MEDIAPIPE_DIRECT:
                self._init_mediapipe_direct_components()
            else:  # FALLBACK
                self._init_fallback_components()
                
        except Exception as e:
            self.logger.error(f"ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰åˆæœŸåŒ–å¤±æ•— ({self.current_backend.value}): {e}")
            self._fallback_to_next_backend()
    
    def _init_modular_gpu_components(self):
        """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†é›¢GPUæœ€é©åŒ–ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–"""
        # GPU ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã¯æ—¢ã«åˆæœŸåŒ–æ¸ˆã¿
        # å€‹åˆ¥æ¤œå‡ºå™¨ã‚‚æ—¢ã«åˆæœŸåŒ–æ¸ˆã¿
        self.logger.info("âš¡ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†é›¢GPUæœ€é©åŒ–ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ ã‚¢ã‚¯ãƒ†ã‚£ãƒ–")
    
    def _init_modular_cpu_components(self):
        """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†é›¢CPUå‡¦ç†ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–"""
        try:
            from .face_detector import FaceDetector
            from .hand_detector import HandDetector
            
            # CPUæœ€é©åŒ–è¨­å®š
            quality_config = self.quality_configs[self.performance_level]
            cpu_config = self.config.copy()
            cpu_config.update(quality_config)
            cpu_config['gpu_optimization'] = False
            
            self.face_detector = FaceDetector(cpu_config)
            self.hand_detector = HandDetector(cpu_config)
            
            self.logger.info("ğŸ”§ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†é›¢CPUå‡¦ç†ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ ã‚¢ã‚¯ãƒ†ã‚£ãƒ–")
            
        except Exception as e:
            self.logger.error(f"ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†é›¢CPUå‡¦ç†ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _init_mediapipe_direct_components(self):
        """MediaPipeç›´æ¥å‡¦ç†ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–"""
        try:
            import mediapipe as mp
            
            self.mp_face_mesh = mp.solutions.face_mesh
            self.mp_hands = mp.solutions.hands
            
            # ç¾åœ¨ã®å“è³ªè¨­å®šå–å¾—
            quality_config = self.quality_configs[self.performance_level]
            
            # Face MeshåˆæœŸåŒ–
            self.face_mesh = self.mp_face_mesh.FaceMesh(
                static_image_mode=False,
                max_num_faces=quality_config['max_num_faces'],
                refine_landmarks=quality_config['refine_landmarks'],
                min_detection_confidence=quality_config['min_detection_confidence'],
                min_tracking_confidence=quality_config['min_tracking_confidence']
            )
            
            # HandsåˆæœŸåŒ–
            self.hands = self.mp_hands.Hands(
                static_image_mode=False,
                max_num_hands=quality_config['max_num_hands'],
                min_detection_confidence=quality_config['min_detection_confidence'],
                min_tracking_confidence=quality_config['min_tracking_confidence']
            )
            
            self.logger.info("ğŸ“¡ MediaPipeç›´æ¥å‡¦ç†ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ ã‚¢ã‚¯ãƒ†ã‚£ãƒ–")
            
        except Exception as e:
            self.logger.error(f"MediaPipeç›´æ¥å‡¦ç†ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _init_fallback_components(self):
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–"""
        self.logger.info("ğŸ›¡ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ ã‚¢ã‚¯ãƒ†ã‚£ãƒ–")
    
    def _init_camera(self):
        """ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–"""
        try:
            camera_config = self.config.get('camera', {})
            device_id = camera_config.get('device_id', 0)
            
            self.camera = cv2.VideoCapture(device_id)
            
            if not self.camera.isOpened():
                self.logger.warning(f"ã‚«ãƒ¡ãƒ© {device_id} ã‚’é–‹ã‘ã¾ã›ã‚“ï¼ˆãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã§ç¶™ç¶šï¼‰")
                return
            
            # ã‚«ãƒ¡ãƒ©è¨­å®š
            width = camera_config.get('width', 1920)
            height = camera_config.get('height', 1080)
            fps = camera_config.get('fps', 30)
            
            self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, width)
            self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
            self.camera.set(cv2.CAP_PROP_FPS, fps)
            self.camera.set(cv2.CAP_PROP_BUFFERSIZE, 1)
            
            self.logger.info(f"ğŸ“¹ ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–æˆåŠŸ: {width}x{height}@{fps}fps")
            
        except Exception as e:
            self.logger.warning(f"ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}ï¼ˆãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã§ç¶™ç¶šï¼‰")
    
    def _log_initialization_summary(self):
        """åˆæœŸåŒ–ã‚µãƒãƒªãƒ¼ãƒ­ã‚°"""
        self.logger.info("="*60)
        self.logger.info("ğŸŒŠ Aqua Mirror æœ€çµ‚çµ±åˆVisionProcessor åˆæœŸåŒ–å®Œäº†")
        self.logger.info(f"ğŸ¯ ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰: {self.current_backend.value}")
        self.logger.info(f"âš¡ GPUåŠ é€Ÿ: {'æœ‰åŠ¹' if self.gpu_processor else 'ç„¡åŠ¹'}")
        self.logger.info(f"ğŸšï¸ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«: {self.performance_level.value}")
        self.logger.info(f"ğŸ¥ ç›®æ¨™FPS: {self.target_fps}")
        self.logger.info(f"ğŸ”„ é©å¿œçš„å“è³ªåˆ¶å¾¡: {'æœ‰åŠ¹' if self.adaptive_quality else 'ç„¡åŠ¹'}")
        self.logger.info("="*60)
    
    def process_frame(self, frame: Optional[np.ndarray] = None) -> Dict[str, Any]:
        """çµ±åˆãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ï¼ˆãƒ¡ã‚¤ãƒ³APIï¼‰"""
        start_time = time.time()
        
        try:
            # ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—
            if frame is None:
                frame = self._get_camera_frame()
            
            if frame is None:
                return self.last_detection_result
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—åˆ¶å¾¡
            quality_config = self.quality_configs[self.performance_level]
            if hasattr(self, '_frame_skip_counter'):
                if self._frame_skip_counter < quality_config['frame_skip_max']:
                    self._frame_skip_counter += 1
                    return self.last_detection_result
                else:
                    self._frame_skip_counter = 0
            else:
                self._frame_skip_counter = 0
            
            # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰åˆ¥å‡¦ç†
            if self.current_backend in [VisionBackend.MODULAR_GPU, VisionBackend.MODULAR_CPU]:
                result = self._process_with_modular_backend(frame)
            elif self.current_backend == VisionBackend.MEDIAPIPE_DIRECT:
                result = self._process_with_mediapipe_direct(frame)
            else:  # FALLBACK
                result = self._process_with_fallback(frame)
            
            # å‡¦ç†æ™‚é–“ãƒ»çµ±è¨ˆæ›´æ–°
            processing_time = time.time() - start_time
            self._update_processing_stats(processing_time, True)
            
            # çµæœã«å‡¦ç†æƒ…å ±è¿½åŠ 
            result.update({
                'processing_time': processing_time,
                'processing_backend': self.current_backend.value,
                'performance_level': self.performance_level.value,
                'gpu_acceleration': self.gpu_processor is not None,
                'timestamp': time.time()
            })
            
            # é©å¿œçš„å“è³ªåˆ¶å¾¡
            if self.adaptive_quality:
                self._adapt_performance()
            
            self.last_detection_result = result
            return result
            
        except Exception as e:
            return self._handle_processing_error(e, start_time)
    
    def _process_with_modular_backend(self, frame: np.ndarray) -> Dict[str, Any]:
        """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†é›¢ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã§ã®å‡¦ç†"""
        try:
            # detectorãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
            if not self.face_detector or not self.hand_detector:
                self.logger.warning("Detector not initialized for modular backend.")
                return self.last_detection_result

            # GPUå‰å‡¦ç†ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
            if (self.current_backend == VisionBackend.MODULAR_GPU and 
                self.gpu_processor):
                processed_frame = self.gpu_processor.process_frame_optimized(frame)
                if processed_frame is None:
                    processed_frame = frame
            else:
                # CPUå‰å‡¦ç†
                quality_config = self.quality_configs[self.performance_level]
                target_resolution = quality_config['resolution']
                processed_frame = cv2.resize(frame, target_resolution)
                processed_frame = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB)
            
            # ä¸¦åˆ—æ¤œå‡ºå‡¦ç†
            face_future = self.executor.submit(self.face_detector.detect_face, processed_frame)
            hand_future = self.executor.submit(self.hand_detector.detect_hands, processed_frame)
            
            try:
                face_result = face_future.result(timeout=0.05)
                hand_result = hand_future.result(timeout=0.05)
            except:
                # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚ã¯å‰å›çµæœè¿”å´
                return self.last_detection_result
            
            # çµæœçµ±åˆ
            detection_results = {'face': face_result, 'hand': hand_result}
            return self._integrate_modular_results(detection_results, frame.shape)
            
        except Exception as e:
            self.logger.error(f"ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†é›¢ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return self.last_detection_result
    
    def _process_with_mediapipe_direct(self, frame: np.ndarray) -> Dict[str, Any]:
        """MediaPipeç›´æ¥å‡¦ç†"""
        try:
            # MediaPipeã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
            if not self.face_mesh or not self.hands:
                self.logger.warning("MediaPipe components not initialized for direct backend.")
                return self.last_detection_result

            # å‰å‡¦ç†
            quality_config = self.quality_configs[self.performance_level]
            target_resolution = quality_config['resolution']
            
            resized_frame = cv2.resize(frame, target_resolution)
            rgb_frame = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)
            
            # MediaPipeå‡¦ç†
            face_results = self.face_mesh.process(rgb_frame)
            hand_results = self.hands.process(rgb_frame)
            
            # çµæœè§£æ
            return self._analyze_mediapipe_results(face_results, hand_results, frame.shape)
            
        except Exception as e:
            self.logger.error(f"MediaPipeç›´æ¥å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return self.last_detection_result
    
    def _process_with_fallback(self, frame: np.ndarray) -> Dict[str, Any]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†"""
        result = self.last_detection_result.copy()
        result['frame_shape'] = frame.shape
        result['processing_backend'] = 'fallback'
        return result
    
    def _get_camera_frame(self) -> Optional[np.ndarray]:
        """ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—"""
        if not self.camera or not self.camera.isOpened():
            return None
        
        ret, frame = self.camera.read()
        return frame if ret else None
    
    def _integrate_modular_results(self, detection_results: Dict[str, Any], frame_shape: Tuple[int, ...]) -> Dict[str, Any]:
        """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†é›¢çµæœçµ±åˆ"""
        try:
            integrated = self._create_default_result()
            integrated['frame_shape'] = frame_shape
            
            # é¡”æ¤œå‡ºçµæœçµ±åˆ
            face_data = detection_results.get('face')
            if face_data:
                integrated.update({
                    'face_detected': face_data.get('face_detected', False),
                    'face_landmarks': face_data.get('face_landmarks'),
                    'face_center': face_data.get('face_center'),
                    'face_distance': face_data.get('face_distance', float('inf')),
                    'face_rotation': face_data.get('face_rotation', {}),
                    'face_bbox': face_data.get('face_bbox', (0, 0, 0, 0)),
                    'face_count': face_data.get('face_count', 0)
                })
                
                if face_data.get('face_detected'):
                    integrated['confidence_scores']['face'] = face_data.get('confidence', 0.8)
            
            # æ‰‹æ¤œå‡ºçµæœçµ±åˆ
            hand_data = detection_results.get('hand')
            if hand_data:
                integrated.update({
                    'hands_detected': hand_data.get('hands_detected', False),
                    'hand_landmarks': hand_data.get('hand_landmarks'),
                    'hand_positions': hand_data.get('hand_positions', []),
                    'hand_count': hand_data.get('hand_count', 0),
                    'hands_info': hand_data.get('hands', [])
                })
                
                # ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼æŠ½å‡º
                integrated['hand_gestures'] = self._extract_gestures(hand_data)
                
                if hand_data.get('hands_detected'):
                    for i, hand_info in enumerate(hand_data.get('hands', [])):
                        if 'confidence' in hand_info:
                            integrated['confidence_scores'][f'hand_{i}'] = hand_info['confidence']
            
            # ç›¸äº’ä½œç”¨åˆ†æ
            integrated['interaction_data'] = self._analyze_interactions(integrated)
            
            # çµ±è¨ˆæ›´æ–°
            if integrated.get('hand_gestures'):
                self.stats['gesture_detections'] += len(integrated['hand_gestures'])
            
            if integrated['interaction_data'].get('face_hand_proximity'):
                self.stats['interaction_detections'] += 1
            
            return integrated
            
        except Exception as e:
            self.logger.error(f"ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†é›¢çµæœçµ±åˆã‚¨ãƒ©ãƒ¼: {e}")
            return self.last_detection_result
    
    def _analyze_mediapipe_results(self, face_results, hand_results, frame_shape: Tuple[int, ...]) -> Dict[str, Any]:
        """MediaPipeç›´æ¥å‡¦ç†çµæœè§£æ"""
        try:
            result = self._create_default_result()
            result['frame_shape'] = frame_shape
            
            # é¡”æ¤œå‡ºè§£æ
            if face_results and face_results.multi_face_landmarks:
                result['face_detected'] = True
                result['face_landmarks'] = face_results
                
                face_landmarks = face_results.multi_face_landmarks[0]
                nose_tip = face_landmarks.landmark[1]
                result['face_center'] = (nose_tip.x, nose_tip.y, nose_tip.z)
                result['face_distance'] = self._calculate_face_distance(face_landmarks)
                result['confidence_scores']['face'] = 0.8
            
            # æ‰‹æ¤œå‡ºè§£æ
            if hand_results and hand_results.multi_hand_landmarks:
                result['hands_detected'] = True
                result['hand_landmarks'] = hand_results.multi_hand_landmarks
                result['hand_count'] = len(hand_results.multi_hand_landmarks)
                
                for i, hand_landmarks in enumerate(hand_results.multi_hand_landmarks):
                    wrist = hand_landmarks.landmark[0]
                    result['hand_positions'].append((wrist.x, wrist.y))
                    
                    if i < len(hand_results.multi_handedness):
                        confidence = hand_results.multi_handedness[i].classification[0].score
                        result['confidence_scores'][f'hand_{i}'] = confidence
            
            # ç›¸äº’ä½œç”¨åˆ†æ
            result['interaction_data'] = self._analyze_interactions(result)
            
            return result
            
        except Exception as e:
            self.logger.error(f"MediaPipeç›´æ¥å‡¦ç†çµæœè§£æã‚¨ãƒ©ãƒ¼: {e}")
            return self.last_detection_result
    
    def _extract_gestures(self, hand_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼æŠ½å‡º"""
        try:
            gestures = []
            hands_info = hand_data.get('hands', [])
            
            for hand_info in hands_info:
                gesture = hand_info.get('gesture', 'unknown')
                if gesture != 'unknown':
                    gestures.append({
                        'type': gesture,
                        'handedness': hand_info.get('handedness', 'Unknown'),
                        'position': hand_info.get('wrist_position', (0, 0, 0)),
                        'confidence': hand_info.get('confidence', 0.0)
                    })
            
            return gestures
            
        except Exception as e:
            self.logger.error(f"ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _analyze_interactions(self, integrated_data: Dict[str, Any]) -> Dict[str, Any]:
        """é¡”ã¨æ‰‹ã®ç›¸äº’ä½œç”¨åˆ†æ"""
        try:
            interaction = {
                'face_hand_proximity': False,
                'hand_near_face': False,
                'pointing_at_face': False,
                'gesture_active': False,
                'proximity_distance': float('inf'),
                'interaction_type': 'none'
            }
            
            # é¡”ã¨æ‰‹ã®è·é›¢åˆ†æ
            if (integrated_data.get('face_detected') and 
                integrated_data.get('hands_detected')):
                
                face_center = integrated_data.get('face_center')
                hand_positions = integrated_data.get('hand_positions', [])
                
                if face_center and hand_positions:
                    min_distance = float('inf')
                    
                    for hand_pos in hand_positions:
                        # 2Dè·é›¢è¨ˆç®—
                        distance = np.sqrt(
                            (face_center[0] - hand_pos[0])**2 + 
                            (face_center[1] - hand_pos[1])**2
                        )
                        min_distance = min(min_distance, distance)
                        
                        if distance < 0.3:  # æ­£è¦åŒ–åº§æ¨™ã§ã®é–¾å€¤
                            interaction['hand_near_face'] = True
                            interaction['face_hand_proximity'] = True
                            interaction['interaction_type'] = 'proximity'
                    
                    interaction['proximity_distance'] = min_distance
            
            # ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼æ´»æ€§çŠ¶æ…‹
            gestures = integrated_data.get('hand_gestures', [])
            if gestures:
                interaction['gesture_active'] = True
                
                for gesture in gestures:
                    if gesture['type'] == 'point':
                        interaction['pointing_at_face'] = True
                        interaction['interaction_type'] = 'pointing'
                    elif gesture['type'] in ['wave', 'peace', 'thumbs_up']:
                        interaction['interaction_type'] = 'gesture'
            
            return interaction
            
        except Exception as e:
            self.logger.error(f"ç›¸äº’ä½œç”¨åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def _calculate_face_distance(self, face_landmarks) -> float:
        """é¡”è·é›¢è¨ˆç®—"""
        try:
            left_face = face_landmarks.landmark[234]
            right_face = face_landmarks.landmark[454]
            
            face_width = abs(right_face.x - left_face.x)
            estimated_distance = 0.14 / (face_width + 1e-6)
            
            return min(estimated_distance, 5.0)
            
        except Exception as e:
            self.logger.error(f"é¡”è·é›¢è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return float('inf')
    
    def _update_processing_stats(self, processing_time: float, success: bool):
        """å‡¦ç†çµ±è¨ˆæ›´æ–°"""
        self.processing_times.append(processing_time)
        self.stats['total_frames'] += 1
        
        if success:
            self.stats['successful_frames'] += 1
        else:
            self.stats['failed_frames'] += 1
        
        # å‡¦ç†æ™‚é–“çµ±è¨ˆæ›´æ–°
        if self.processing_times:
            self.stats['avg_processing_time'] = sum(self.processing_times) / len(self.processing_times)
        
        # FPSè¨ˆç®—
        self._update_fps()
    
    def _update_fps(self):
        """FPSæ›´æ–°"""
        self.frame_count += 1
        current_time = time.time()
        
        if current_time - self.last_fps_time >= 1.0:
            self.current_fps = self.frame_count / (current_time - self.last_fps_time)
            self.frame_count = 0
            self.last_fps_time = current_time
    
    def _adapt_performance(self):
        """é©å¿œçš„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ¶å¾¡"""
        if len(self.processing_times) < 10:
            return
        
        target_frame_time = 1.0 / self.target_fps
        avg_processing_time = self.stats['avg_processing_time']
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«èª¿æ•´
        if avg_processing_time > target_frame_time * 1.5:
            self._decrease_performance_level()
        elif avg_processing_time < target_frame_time * 0.7 and self.current_fps > self.target_fps * 1.1:
            self._increase_performance_level()
    
    def _decrease_performance_level(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«ä½ä¸‹"""
        current_levels = list(PerformanceLevel)
        current_index = current_levels.index(self.performance_level)
        
        if current_index < len(current_levels) - 1:
            old_level = self.performance_level
            self.performance_level = current_levels[current_index + 1]
            
            self.logger.info(f"ğŸ”½ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«ä½ä¸‹: {old_level.value} â†’ {self.performance_level.value}")
            self._reinit_backend_with_quality()
    
    def _increase_performance_level(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«å‘ä¸Š"""
        current_levels = list(PerformanceLevel)
        current_index = current_levels.index(self.performance_level)
        
        if current_index > 0:
            old_level = self.performance_level
            self.performance_level = current_levels[current_index - 1]
            
            self.logger.info(f"ğŸ”¼ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«å‘ä¸Š: {old_level.value} â†’ {self.performance_level.value}")
            self._reinit_backend_with_quality()
    
    def _reinit_backend_with_quality(self):
        """å“è³ªè¨­å®šã§ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å†åˆæœŸåŒ–"""
        try:
            self._initialize_current_backend()
        except Exception as e:
            self.logger.warning(f"ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å†åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _handle_processing_error(self, error: Exception, start_time: float) -> Dict[str, Any]:
        """å‡¦ç†ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"""
        processing_time = time.time() - start_time
        self._update_processing_stats(processing_time, False)
        
        self.logger.warning(f"ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚¨ãƒ©ãƒ¼ ({self.current_backend.value}): {error}")
        
        # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        self._fallback_to_next_backend()
        
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å‰å›çµæœè¿”å´
        result = self.last_detection_result.copy()
        result.update({
            'processing_time': processing_time,
            'error_occurred': True,
            'error_message': str(error)
        })
        
        return result
    
    def _fallback_to_next_backend(self):
        """æ¬¡ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        priority = [
            VisionBackend.MODULAR_GPU,
            VisionBackend.MODULAR_CPU,
            VisionBackend.MEDIAPIPE_DIRECT,
            VisionBackend.FALLBACK
        ]
        
        try:
            current_index = priority.index(self.current_backend)
        except ValueError:
            current_index = -1
        
        # æ¬¡ã®åˆ©ç”¨å¯èƒ½ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’æ¢ç´¢
        for i in range(current_index + 1, len(priority)):
            if priority[i] in self.available_backends:
                old_backend = self.current_backend
                self.current_backend = priority[i]
                self.stats['backend_switches'] += 1
                
                self.logger.warning(f"ğŸ”„ ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰åˆ‡æ›¿: {old_backend.value} â†’ {self.current_backend.value}")
                
                try:
                    self._initialize_current_backend()
                    break
                except Exception as e:
                    self.logger.error(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆæœŸåŒ–å¤±æ•—: {e}")
                    continue
    
    def get_debug_info(self) -> Dict[str, Any]:
        """ãƒ‡ãƒãƒƒã‚°æƒ…å ±å–å¾—ï¼ˆAPIäº’æ›ï¼‰"""
        result = self.last_detection_result
        
        debug_info = {
            'Face': 'YES' if result.get('face_detected') else 'NO',
            'Hands': 'YES' if result.get('hands_detected') else 'NO',
            'Face Distance': f"{result.get('face_distance', 0):.3f}m",
            'Hand Count': result.get('hand_count', 0),
            'Gestures': len(result.get('hand_gestures', [])),
            'Interaction': result.get('interaction_data', {}).get('interaction_type', 'none'),
            'Backend': self.current_backend.value,
            'GPU': 'ON' if self.gpu_processor else 'OFF',
            'FPS': f"{self.current_fps:.1f}",
            'Performance': self.performance_level.value,
            'Success Rate': f"{(self.stats['successful_frames'] / max(1, self.stats['total_frames']) * 100):.1f}%"
        }
        
        return debug_info
    
    def get_system_info(self) -> Dict[str, Any]:
        """è©³ç´°ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±"""
        return {
            'current_backend': self.current_backend.value,
            'available_backends': [b.value for b in self.available_backends],
            'performance_level': self.performance_level.value,
            'gpu_acceleration': self.gpu_processor is not None,
            'adaptive_quality': self.adaptive_quality,
            'target_fps': self.target_fps,
            'current_fps': self.current_fps,
            'processing_stats': self.stats.copy(),
            'interaction_detections': self.stats.get('interaction_detections', 0),
            'gesture_detections': self.stats.get('gesture_detections', 0)
        }
    
    def force_backend(self, backend_name: str) -> bool:
        """ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å¼·åˆ¶åˆ‡æ›¿"""
        try:
            backend = VisionBackend(backend_name)
            if backend in self.available_backends:
                old_backend = self.current_backend
                self.current_backend = backend
                self._initialize_current_backend()
                
                self.logger.info(f"ğŸ¯ ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å¼·åˆ¶åˆ‡æ›¿: {old_backend.value} â†’ {backend.value}")
                return True
            else:
                self.logger.warning(f"ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ {backend_name} ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“")
                return False
                
        except ValueError:
            self.logger.error(f"ä¸æ­£ãªãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å: {backend_name}")
            return False
    
    def set_performance_level(self, level_name: str) -> bool:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«æ‰‹å‹•è¨­å®š"""
        try:
            level = PerformanceLevel(level_name)
            old_level = self.performance_level
            self.performance_level = level
            
            self._reinit_backend_with_quality()
            
            self.logger.info(f"ğŸšï¸ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«è¨­å®š: {old_level.value} â†’ {level.value}")
            return True
            
        except ValueError:
            self.logger.error(f"ä¸æ­£ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«: {level_name}")
            return False
    
    def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾ï¼ˆAPIäº’æ›ï¼‰"""
        self.logger.info("ğŸ§¹ æœ€çµ‚çµ±åˆVisionProcessor ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–‹å§‹...")
        
        try:
            # å€‹åˆ¥æ¤œå‡ºå™¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if self.face_detector and hasattr(self.face_detector, 'cleanup'):
                self.face_detector.cleanup()
            if self.hand_detector and hasattr(self.hand_detector, 'cleanup'):
                self.hand_detector.cleanup()
            
            # MediaPipeç›´æ¥å‡¦ç†ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if self.face_mesh:
                self.face_mesh.close()
            if self.hands:
                self.hands.close()
            
            # ã‚«ãƒ¡ãƒ©ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if self.camera:
                self.camera.release()
            
            # GPU ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if self.gpu_processor and hasattr(self.gpu_processor, 'cleanup'):
                self.gpu_processor.cleanup()
            
            # ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if self.executor:
                self.executor.shutdown(wait=True)
            
            # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            gc.collect()
            
            self.logger.info("âœ… æœ€çµ‚çµ±åˆVisionProcessor ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
            
        except Exception as e:
            self.logger.warning(f"ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
        
        print("VisionProcessor ãŒã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸ")
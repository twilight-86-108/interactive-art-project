# src/vision/vision_processor_v10.py - MediaPipe 0.10.xå®Œå…¨å¯¾å¿œç‰ˆ
import cv2
import numpy as np
import mediapipe as mp
import os
import urllib.request
from typing import Optional, Dict, Any

class VisionProcessorV10:
    """MediaPipe 0.10.xå¯¾å¿œç‰ˆç”»åƒå‡¦ç†ã‚¯ãƒ©ã‚¹ - æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã¨å®Œå…¨äº’æ›"""
    
    def __init__(self, config):
        self.config = config
        self.camera = None
        self.last_detection_result = {}
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹
        self.models_dir = "assets/models"
        os.makedirs(self.models_dir, exist_ok=True)
        
        # æ¤œå‡ºå™¨åˆæœŸåŒ–
        self._download_and_init_models()
        self._init_camera()
        
        print("âœ… MediaPipe 0.10.x VisionProcessor åˆæœŸåŒ–å®Œäº†")
    
    def _download_and_init_models(self):
        """ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»åˆæœŸåŒ–"""
        # é¡”æ¤œå‡ºãƒ¢ãƒ‡ãƒ«
        self.face_model_path = os.path.join(self.models_dir, "face_landmarker.task")
        if not os.path.exists(self.face_model_path):
            print("ğŸ“¥ é¡”æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
            try:
                urllib.request.urlretrieve(
                    "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task",
                    self.face_model_path
                )
                print("âœ… é¡”æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†")
            except Exception as e:
                print(f"âŒ é¡”æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
                self.face_model_path = None
        
        # æ‰‹æ¤œå‡ºãƒ¢ãƒ‡ãƒ«
        self.hand_model_path = os.path.join(self.models_dir, "hand_landmarker.task")
        if not os.path.exists(self.hand_model_path):
            print("ğŸ“¥ æ‰‹æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
            try:
                urllib.request.urlretrieve(
                    "https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task",
                    self.hand_model_path
                )
                print("âœ… æ‰‹æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†")
            except Exception as e:
                print(f"âŒ æ‰‹æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
                self.hand_model_path = None
        
        # æ¤œå‡ºå™¨åˆæœŸåŒ–
        self._init_face_detector()
        self._init_hand_detector()
    
    def _init_face_detector(self):
        """é¡”æ¤œå‡ºå™¨åˆæœŸåŒ–"""
        if not self.face_model_path or not os.path.exists(self.face_model_path):
            self.face_landmarker = None
            return
        
        try:
            from mediapipe.tasks import python
            from mediapipe.tasks.python import vision
            
            base_options = python.BaseOptions(model_asset_path=self.face_model_path)
            options = vision.FaceLandmarkerOptions(
                base_options=base_options,
                output_face_blendshapes=False,
                output_facial_transformation_matrixes=False,
                num_faces=self.config.get('detection', {}).get('max_num_faces', 1)
            )
            self.face_landmarker = vision.FaceLandmarker.create_from_options(options)
            print("âœ… é¡”æ¤œå‡ºå™¨åˆæœŸåŒ–æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ é¡”æ¤œå‡ºå™¨åˆæœŸåŒ–å¤±æ•—: {e}")
            self.face_landmarker = None
    
    def _init_hand_detector(self):
        """æ‰‹æ¤œå‡ºå™¨åˆæœŸåŒ–"""
        if not self.hand_model_path or not os.path.exists(self.hand_model_path):
            self.hand_landmarker = None
            return
        
        try:
            from mediapipe.tasks import python
            from mediapipe.tasks.python import vision
            
            base_options = python.BaseOptions(model_asset_path=self.hand_model_path)
            options = vision.HandLandmarkerOptions(
                base_options=base_options,
                num_hands=self.config.get('detection', {}).get('max_num_hands', 2)
            )
            self.hand_landmarker = vision.HandLandmarker.create_from_options(options)
            print("âœ… æ‰‹æ¤œå‡ºå™¨åˆæœŸåŒ–æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ æ‰‹æ¤œå‡ºå™¨åˆæœŸåŒ–å¤±æ•—: {e}")
            self.hand_landmarker = None
    
    def _init_camera(self):
        """ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–ï¼ˆæ—¢å­˜ã‚³ãƒ¼ãƒ‰ã¨åŒã˜ï¼‰"""
        camera_config = self.config.get('camera', {})
        device_id = camera_config.get('device_id', 0)
        
        self.camera = cv2.VideoCapture(device_id)
        
        if not self.camera.isOpened():
            print(f"âŒ ã‚«ãƒ¡ãƒ© {device_id} ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“")
            return
        
        # ã‚«ãƒ¡ãƒ©è¨­å®š
        self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, camera_config.get('width', 1920))
        self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, camera_config.get('height', 1080))
        self.camera.set(cv2.CAP_PROP_FPS, camera_config.get('fps', 30))
        
        print("âœ… ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–å®Œäº†")
    
    def process_frame(self):
        """ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç† - æ—¢å­˜APIã¨å®Œå…¨äº’æ›"""
        if not self.camera or not self.camera.isOpened():
            return self.last_detection_result
        
        ret, frame = self.camera.read()
        if not ret:
            return self.last_detection_result
        
        # BGR to RGBå¤‰æ›
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # MediaPipe Imageä½œæˆ
        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)
        
        # æ¤œå‡ºå®Ÿè¡Œ
        face_results = self._detect_face(mp_image)
        hand_results = self._detect_hands(mp_image)
        
        # çµæœã‚’æ—¢å­˜å½¢å¼ã«å¤‰æ›
        detection_result = self._convert_to_legacy_format(face_results, hand_results, frame.shape)
        self.last_detection_result = detection_result
        
        return detection_result
    
    def _detect_face(self, mp_image):
        """é¡”æ¤œå‡º"""
        if not self.face_landmarker:
            return None
        
        try:
            return self.face_landmarker.detect(mp_image)
        except Exception as e:
            print(f"é¡”æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _detect_hands(self, mp_image):
        """æ‰‹æ¤œå‡º"""
        if not self.hand_landmarker:
            return None
        
        try:
            return self.hand_landmarker.detect(mp_image)
        except Exception as e:
            print(f"æ‰‹æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _convert_to_legacy_format(self, face_results, hand_results, frame_shape):
        """æ–°APIçµæœã‚’æ—¢å­˜å½¢å¼ã«å¤‰æ›"""
        result = {
            'face_detected': False,
            'hands_detected': False,
            'face_center': None,
            'face_distance': float('inf'),
            'hand_positions': [],
            'frame_shape': frame_shape,
            'face_landmarks': None,  # æ„Ÿæƒ…èªè­˜ç”¨
            'hand_landmarks': None   # ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼èªè­˜ç”¨
        }
        
        # é¡”æ¤œå‡ºçµæœå¤‰æ›
        if face_results and face_results.face_landmarks:
            result['face_detected'] = True
            result['face_landmarks'] = face_results  # æ„Ÿæƒ…èªè­˜ã§ä½¿ç”¨
            
            # æœ€åˆã®é¡”ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯å–å¾—
            if len(face_results.face_landmarks) > 0:
                landmarks = face_results.face_landmarks[0]
                
                # é¼»ã®å…ˆç«¯ï¼ˆãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯1ï¼‰ã‚’ä¸­å¿ƒç‚¹ã¨ã™ã‚‹
                if len(landmarks) > 1:
                    nose_tip = landmarks[1]
                    result['face_center'] = (nose_tip.x, nose_tip.y, nose_tip.z)
                    result['face_distance'] = abs(nose_tip.z)
        
        # æ‰‹æ¤œå‡ºçµæœå¤‰æ›
        if hand_results and hand_results.hand_landmarks:
            result['hands_detected'] = True
            result['hand_landmarks'] = hand_results  # ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼èªè­˜ã§ä½¿ç”¨
            
            for hand_landmarks in hand_results.hand_landmarks:
                if len(hand_landmarks) > 0:
                    # æ‰‹é¦–ï¼ˆãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯0ï¼‰ã®åº§æ¨™ã‚’å–å¾—
                    wrist = hand_landmarks[0]
                    result['hand_positions'].append((wrist.x, wrist.y))
        
        return result
    
    def get_debug_info(self):
        """ãƒ‡ãƒãƒƒã‚°æƒ…å ±å–å¾— - æ—¢å­˜APIã¨äº’æ›"""
        result = self.last_detection_result
        return {
            'Face': 'YES' if result.get('face_detected') else 'NO',
            'Hands': 'YES' if result.get('hands_detected') else 'NO',
            'Face Dist': f"{result.get('face_distance', 0):.3f}",
            'Hand Count': len(result.get('hand_positions', [])),
            'API Version': 'MediaPipe 0.10.x',
            'Face Model': 'OK' if self.face_landmarker else 'FAILED',
            'Hand Model': 'OK' if self.hand_landmarker else 'FAILED'
        }
    
    def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾ - æ—¢å­˜APIã¨äº’æ›"""
        if self.camera:
            self.camera.release()
        print("VisionProcessorV10 ãŒã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸ")